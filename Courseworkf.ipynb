{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image Repository "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will aim to apply facial recognition to images with masks whilst also detecting the gender of the person to determine if they are female or male. This project assumes that there are only two genders and did not account for transgender or non binary people. To do this an image repository has been compiled named 'images' containing four subfolders named 'femalemask','femalenomask','malemask', and 'malenomask'. These images have been sourced from two kaggle datasets.\n",
    "\n",
    "The image repository first used the Gupta Human Faces (HF) dataset (2020). This data had sufficient data for masked individuals of both genders however it was lacking in the amount of unmasked faces. Especially unmasked females, which would be crucial for the model. Therefore, a second dataset The Larxel Face Mask Detection(FMD)(2020) was introduced extracting 250 images of female faces and 250 male faces without masks.  \n",
    "\n",
    "Once the two datasets were collected, the images within them were manually divided to each subfolder depending on whether they were male or female or had a mask on. Group photos within the datasets were cropped to extract multiple faces from each photo. Resulting in four subfolders containing female faces with a mask 'femalemask', female faces with no mask 'femalenomask', male faces with a mask 'malemask', and male faces with no mask 'malenomask'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUPTA, A., 2020. Human Faces, A web scraped dataset of human faces suggested for image processing models. [online]. US: Kaggle. Available from: https://www.kaggle.com/ashwingupta3012/human-faces URL [16th April 2021].\n",
    "\n",
    "LARXEL., 2020. Face Mask Detection. [online]. US: Kaggle. Available from: :https://www.kaggle.com/andrewmvd/face-mask-detection URL [16th April 2021]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creation of multiple variations of the original repository based on data processing techniques. For this step,\n",
    "students must apply techniques such as image pre-processing (e.g. thresholding, cleaning, denoising, filtering),\n",
    "feature extraction, image/feature augmentation and class decomposition to store replicas of the original\n",
    "dataset inside appropriate data structures, such as NumPy arrays, Pandas data frames, etc.\n",
    "\n",
    "\n",
    "The student\n",
    "implemented an optimal\n",
    "function which loads the\n",
    "data repository into a\n",
    "proper Python data\n",
    "structure.\n",
    "Images were correctly\n",
    "transformed before the\n",
    "creation of the original\n",
    "data repository\n",
    "structure.\n",
    "A wide variety of\n",
    "additional datasets were\n",
    "created, showing an\n",
    "exceptional\n",
    "understanding of recent\n",
    "and complex image preprocessing, feature\n",
    "extraction,\n",
    "image/feature\n",
    "augmentation and class\n",
    "decomposition\n",
    "techniques.\n",
    "All methodologies used\n",
    "are clearly justified and\n",
    "explained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three aims of the pre-processing stage:\n",
    "\n",
    " - Resize Image Repository\n",
    " - Binarise Image Repository\n",
    " - Histogram of Gradients(HOG) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resize Image Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pre-processing stage, the images will be resized and then binarised. The images are loaded and resized to 100x100 so that all the images in the repository will be the same size for the classification problem further on. \n",
    "\n",
    "After the images are loaded and resized they are place in a repository named datarepo. Then another repository is created to store them as flattened numpy dataframes in originalrepo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binarised  Image Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resizing the images they are then binarised. Each image is binarised and have a threshold added to the images. Creating a copy of the image, the function iterates over the numpy array for all rows and columns of the image, comparing the pixel value to the threshold. When the pixel's value is smaller than the threshold, the pixel's value is transformed to zero. If the pixel's value is greater than the threshold it is converted to 255. This is then saved into a repository "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram of Gradients(HOG) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract facial features from the images to allow for the classification a technique using the Histogram of Gradients(HOG) is applied to the image repository. \n",
    "\n",
    "The method counts the number of times a gradient orientation appears in a specific area of an image. Turning a 64x128x3 image into a feature vector with a length of 3780 pixels.The image's x and y gradients, as well as its magnitude, are determined using this method. The gradients are calculated by splitting the image into patches.\n",
    "\n",
    "With the following code it is possible to load the dataset, resize/binarise the images, and then create an additional image repository using Histogram of Gradients (HOG)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the Hog Feature as Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "# Obtaining the HOG gradients of an image\n",
    "from skimage import feature\n",
    "class HOG:\n",
    "    def __init__(self, orientations = 9, pixelsPerCell = (8, 8),\n",
    "        cellsPerBlock = (3, 3), transform = False):\n",
    "        # store the number of orientations, pixels per cell,\n",
    "        # cells per block, and whether or not power law\n",
    "        # compression should be applied\n",
    "        self.orienations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.transform = transform\n",
    "\n",
    "    def describe(self, image):\n",
    "        # compute HOG for the image\n",
    "        hist = feature.hog(image, orientations = self.orienations,\n",
    "            pixels_per_cell = self.pixelsPerCell,\n",
    "            cells_per_block = self.cellsPerBlock,\n",
    "            transform_sqrt = self.transform)\n",
    "        ## return the HOG features\n",
    "        return hist\n",
    "    \n",
    "hog = HOG(orientations = 18, pixelsPerCell = (10, 10), cellsPerBlock = (1, 1), transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Pre-Processing to Image Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will apply the pre-processing to the full repository and store it as a numpy data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the relevant packages\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage import feature\n",
    "from pandas import DataFrame\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from skimage.restoration import denoise_tv_chambolle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "#set the desired width and height\n",
    "resize_factor = 100 # applies for both height and width\n",
    "\n",
    "#set path to the images\n",
    "path = 'images'\n",
    "target =  []\n",
    "datarepo = [] # List to append the images as 2D numpy arrays\n",
    "originalrepo = [] # Create a repo for flattened pixels\n",
    "binarisedrepo = []  # Create a list to append the binarised pixels\n",
    "hogrepo = [] # Create a list to append the HOG features\n",
    "denoiserepo = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "     for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as auto:\n",
    "            if file != \".DS_Store\":\n",
    "                #pre-processing the data\n",
    "                #load each image\n",
    "                image = cv2.imread(root+'/'+file, 0)\n",
    "                 #resize each image\n",
    "                image = cv2.resize(image, (resize_factor, resize_factor))\n",
    "                #assign each image to datarepo\n",
    "                datarepo.append(image)\n",
    "                #flatten each image to origninaldata\n",
    "                originalrepo.append(image.flatten())\n",
    "                #denoise each image\n",
    "                image = denoise_tv_chambolle(image, multichannel=True)\n",
    "                denoiserepo.append(image.flatten())\n",
    "                #binarise each image\n",
    "                _, image = cv2.threshold(image, 180, 255, 0)\n",
    "                #flatten binarised images\n",
    "                binarisedrepo.append(image.flatten())\n",
    "                # Extract HOG and append to HOG repo\n",
    "                hogfeatures = hog.describe(image)\n",
    "                hogrepo.append(hogfeatures)\n",
    "                 # Append the folder where the image is to the target list\n",
    "                target.append(root.replace(path,'').replace('\\\\','')) \n",
    "                \n",
    "                \n",
    "# Convert the repo list into  numpy arrays\n",
    "originalrepo = np.array(originalrepo) \n",
    "binarisedrepo = np.array(binarisedrepo)\n",
    "hogrepo = np.array(hogrepo)\n",
    "denoiserepo = np.array(denoiserepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Class  Number of Samples\n",
      "0    femalemask                348\n",
      "1  femalenomask                285\n",
      "2      malemask                355\n",
      "3    malenomask                285\n",
      "Total images: 1273\n"
     ]
    }
   ],
   "source": [
    "#relevant packages imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target)])\n",
    "\n",
    "# Load as a panda\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results states that there is 348 instances of the class femalemask, 285 instances of the class femalenomask, 355 instances of the class malemask and 285 instances of the class malenomask. Overall, the original repository contains 1273 images stored as a numpy array and can be visualised with the barplot from seaborn below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of target:  1273\n",
      "Size of original repository:  (1273, 10000)\n",
      "Example of original repository: \n",
      "[[222 221 221 ... 242 246 250]\n",
      " [ 40  34  34 ...   0   0   0]\n",
      " [230 228 228 ...  91 111 114]\n",
      " ...\n",
      " [124 124 123 ...  88  95 102]\n",
      " [117 117 118 ... 255 255 255]\n",
      " [145 133 127 ...  66  64  63]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette=\"Blues\")\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Size of target: ', len(target))\n",
    "print('Size of original repository: ', originalrepo.shape)\n",
    "print('Example of original repository: ')\n",
    "print(originalrepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot visualises how male mask has the most number of samples within the data frame with female masks being the second highest number of instances. With females without masks and males without masks with the next highest count repectively. This shows a class imbalance as there is more counts of images with masks than without mask and there is over double the number of males with masks than without.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved Plots as JPG Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Class Distribution Bar Chart\n"
     ]
    }
   ],
   "source": [
    "# Save the image\n",
    "sns_plot.figure.savefig('barchart.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n",
    "print('Saved Class Distribution Bar Chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random OverSampling Repository "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random OverSampling (ROS) is a data based imbalance handling techniques that is applied to the HOG repository. This aims to increase the minority class to provide a balanced dataset. There can be issues when using a non-binary datasets because it is more difficult to establish the minority class however the process is applied below and this augmentation is visualised in the following barplot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "hogrepo_ros, target_ros = ros.fit_resample(hogrepo,target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating class distribution (after ROS)\n",
      "          Class  Number of Samples\n",
      "0    femalemask                355\n",
      "1  femalenomask                355\n",
      "2      malemask                355\n",
      "3    malenomask                355\n",
      "Total images: 1420\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "hogrepo_ros, target_ros = ros.fit_resample(hogrepo,target)\n",
    "\n",
    "print('\\nCalculating class distribution (after ROS)')\n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target_ros)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target_ros):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target_ros)])\n",
    "## Save the histogram as a .csv file   \n",
    "with open('classdistribution_ros.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, hist in enumerate(histo):\n",
    "        filewriter.writerow(hist)\n",
    "## Convert histo into a panda dataframe\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target_ros)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise Class Distribution After ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing class distribution bar chart (after ros)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ROS augmented target:  1420\n",
      "Size of ROS augmented repository:  (1420, 1800)\n",
      "Example of the ROS augmented repository: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette=\"Set2\")\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "print('\\nShowing class distribution bar chart (after ros)')\n",
    "plt.show()\n",
    "\n",
    "print('Size of ROS augmented target: ', len(target_ros))\n",
    "print('Size of ROS augmented repository: ', hogrepo_ros.shape)\n",
    "print('Example of the ROS augmented repository: ')\n",
    "print(hogrepo_ros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the repository has been augmented from 1273 images with 10000, to 1420 images with 1800. Resulting in each class containing 350 instances each and more balanced. However as this is not a binary classification in which random oversampling is most effective on it will be further improved with the application of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot.figure.savefig('barchart_ros.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat this class inbalance the following code will be introduced to create a function that will follow the standard balancing equation to calculate the k values for ech class. This will obtain the number of classes in label list and sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is a  non-Binary datasets they have different class sizes  a special category of balancing methods can be applied to the datasets, which also mitigate the disadvantages of both oversampling and undersampling\n",
    "\n",
    "The Standard Balancing Equation can help calculate the imbalances with the number of clusters representing the total number of instances of a specific class divided by the mean class distribution. A function below is created to follows the standard balancing equation to calculate k for each class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Using Standard Balancing Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of k for each class:  [2, 1, 2, 1]\n",
      "Number of classes after class decomposition:  6\n"
     ]
    }
   ],
   "source": [
    "def standardbalancingequation(target):\n",
    "    import math\n",
    "    \n",
    "    ## Obtain the number of classes in label list and sort\n",
    "    labelsIndexesUnique = list(set(target))\n",
    "    labelsIndexesUnique.sort()\n",
    "    \n",
    "    ## For each class, count the number of instances and calculate ki\n",
    "    k = []\n",
    "    for label in labelsIndexesUnique:\n",
    "        k.append(target.count(label))\n",
    "    avgInst = sum(k)/len(k)\n",
    "    k = [math.floor((ki/avgInst)+1) for ki in k]\n",
    "    print('Values of k for each class: ', k)\n",
    "    return k\n",
    "\n",
    "k_kmeans = standardbalancingequation(target)\n",
    "print('Number of classes after class decomposition: ', sum(k_kmeans))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Decomposition(CD) Using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters for class femalemask: 2\n",
      "Number of clusters for class femalenomask: 1\n",
      "Number of clusters for class malemask: 2\n",
      "Number of clusters for class malenomask: 1\n"
     ]
    }
   ],
   "source": [
    "def CDKmeans(data, target, k): \n",
    "    from sklearn.cluster import KMeans\n",
    "    target_cd = ['']*len(target)\n",
    "    IndexesUnique = list(set(target))\n",
    "    IndexesUnique.sort()\n",
    "    for i, label in enumerate(IndexesUnique):\n",
    "        print('Number of clusters for class '+str(label)+': '+str(k[i]))\n",
    "        \n",
    "        ## Split the dataset\n",
    "        data_tocluster = []\n",
    "        data_tocluster_index = []\n",
    "        for j, dat in enumerate(data):\n",
    "            if target[j]==label:\n",
    "                data_tocluster.append(dat)\n",
    "                data_tocluster_index.append(j)\n",
    "        if 1<k[i]<=len(data_tocluster):\n",
    "            \n",
    "                ## Apply k-means to the list    \n",
    "                kmeans = KMeans(n_clusters=k[i], random_state=0).fit(data_tocluster)\n",
    "                for n, m in enumerate(kmeans.labels_):\n",
    "                    target_cd[data_tocluster_index[n]]=str(label)+'_c'+str(m)\n",
    "        else:\n",
    "            for m in data_tocluster_index:\n",
    "                target_cd[m]=str(label)+'_c0'\n",
    "    return target_cd\n",
    "\n",
    "target_cd = CDKmeans(binarisedrepo, target, k_kmeans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As femalenomask and malenomask is smaller than 2 no clustering is needed. However, femalemask and malemask all have values over 2 therefore floor is applied to give the correct clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Class Distribution After Class Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Class  Number of Samples\n",
      "0    femalemask_c0                348\n",
      "1  femalenomask_c0                285\n",
      "2      malemask_c0                355\n",
      "3    malenomask_c0                285\n",
      "Total images: 1273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target_cd)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target_cd):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target_cd)])\n",
    "\n",
    "        \n",
    "## Convert histo into a panda dataframe\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target_cd)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of the class decomposition method, the size of the augmented pixel repository has remained 1236 rows with 1800 columns. Creating two more classes for the \"original\" repository and placed within target_cd. The repository consists of the 2 female mask classifiers, femalemask_c0 with 64 and femalemask_c1 with 279. A classifier for females without masks (femalenomask_c0) with 277, a classifier for males without masks (malenomask_c0) with 197. With finally 2 male mask classifiers, malemask_c0 with 274 and malemask_c1 with 145. Overall creating six classes in this class decomposition repository.\n",
    "\n",
    "This repository will be converted into a pandas dataframe named original_cd and its class distribution can be visualised below with a barplot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Visualise Class Distribution After Class Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAFzCAYAAAAZnkAuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg20lEQVR4nO3de5SkVX3u8e/DDIgCCgiy8IKDE1CRy6AwJsYoKCIaFRQQkIhEjmgUomZxjHg7eryES2LiFYNGwBwiwQiKmgCKKIoIMwMMw0UigkZ0gnq4i6Iwv/NH7T4WPd09PUhTu2e+n7V6ddV+97vfX23exTxr167qVBWSJElSj9YZdQGSJEnSZAyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbs0ddQGaOZtttlnNmzdv1GVIkiSt0pIlS35RVZuPbzesrsHmzZvH4sWLR12GJEnSKiX50UTtbgOQJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbvnVVWuwW355D/92yc9HXYYkSerMfgtX+jrTbrmyKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6lZXYTXJXya5JsmpMzT+u5McNRNjr+K6JyfZ7/cc4+gk1yW5NsnzH6jaJEmSejZ31AWM83rgBVV1w6gL6UmS7YADgacAjwa+lmTbqrp3tJVJkiTNrG5WVpN8AngCcFaStyf5dJJFSS5Lsnfrc2iSLyT5UpIbkhyR5K9an+8m2bT1e007d2mSzyd52ATXm5/k7CRLknwryZNa+8lJTkhyfpLrkzy71XJNkpOHzj8hyeIkVyV5z1D7MUmuTnJFkr+d4LrvbdeYcO6T7JrkO632S5JsBOwNnFZVd7cgfx2wcJLzD291Lb791v877fmXJEnqUTdhtapeB/wU2B3YAPh6Ve3anh+fZIPWdXvgFQzC2vuBu6pqZ+Ai4JDW54yq2rWqdgKuAQ6b4JInAkdW1dOAo4CPDx3bBHgO8GbgS8DfM1jV3CHJgtbn7VW1C7Aj8OwkO7aw/FLgKVW1I/C+4QsmOQ54FPDnVbVifEFJ1gP+FXhjq30P4FfAY4AfD3W9sbWtpKpOrKpdqmqXh2/8yIm6SJIkzRq9bQMYsyfwkqH9pesDW7XH51fVHcAdSW5jECYBljEIjgDbJ3kfsDGwIXDO8OBJNgSeAXwuyVjzQ4a6fKmqKsky4KaqWtbOuwqYB1wOvDzJ4QzmcEtgO+Bq4NfAp5J8Bfjy0JjvBC6uqsOneN1PBJZX1SKAqrq9XTcT9K0pxpEkSVoj9BpWA+xbVdfepzF5OnD3UNOKoecr+N3rORnYp6qWJjkU2G3c+OsAt1bVgkmuPzzm+OvNTbI1g9XYXavqlrY9YP2quifJQuC5DPaYHsFghRZgEfC0JJtW1c1TvO6JQuiNwOOGnj+WwSq0JEnSGq2bbQDjnAMcObaimGTn1Tx/I2B5knWBg8cfbCuWNyTZv42fJDutxvgPB34J3JZkC+AFbZwNgUdU1b8DbwIWDJ1zNnAM8JW2D3Ui3wMenWTXNt5GSeYCZwEHJnlIC8rbAJesRr2SJEmzUq8rq+8F/gG4ogXWHwIvWo3z3wlcDPyIwfaAicLhwcAJSd4BrAucBiydzuBtxfYy4CrgeuDCdmgj4ItJ1mewSvrmced9rgXVs5K8sKp+Ne74b5IcAHwkyUMZ7Ffdo6quSnI6g20G9wBv8JsAJEnS2iBVbn1cU81/8oI69pSvjroMSZLUmf0Wbj7qElaSZEn78Pp99LoNQJIkSep2G8AaL8mZwNbjmv+6qs6ZqL8kSdLayLA6IlX10lHXIEmS1Du3AUiSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6tbcURegmbPJBnPZb+Hmoy5DkiTpfnNlVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrfmjroAzZx7b/8Zt579kVGXIUnShDbe68hRl6BZwJVVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElSt2YsrCb5yyTXJDl1hsZ/d5KjZmLsB1KS3ZJ8+fcc42lJliW5LsmHk+SBqk+SJKlnM7my+nrghVV18AxeY21xAnA4sE372Wu05UiSJD04ZiSsJvkE8ATgrCRvT/LpJIuSXJZk79bn0CRfSPKlJDckOSLJX7U+302yaev3mnbu0iSfT/KwCa43P8nZSZYk+VaSJ7X2k9tK5HeSXJ9kv9aeJMcnubKtWB7Q2ndL8s0kpyf5zyTHJDk4ySWt3/zW78VJLm61fi3JFq392Ukubz+XJdloXJ27tvYnTDJvGyY5qV3riiT7JtkSeHhVXVRVBXwG2OeB+O8kSZLUuxkJq1X1OuCnwO7ABsDXq2rX9vz4JBu0rtsDrwAWAu8H7qqqnYGLgENanzOqateq2gm4BjhsgkueCBxZVU8DjgI+PnRsS+CZwIuAY1rby4AFwE7AHq2mLduxnYA3AjsArwS2raqFwKeAI1ufbwN/2Go9DXhLaz8KeENVLQD+BPjVWBFJngF8Ati7qq6fZOreCdxWVTtU1Y7A14HHADcO9bmxtU0oyeFJFidZ/Ivb7pysmyRJ0qww90G4xp7AS4b2l64PbNUen19VdwB3JLkN+FJrXwbs2B5vn+R9wMbAhsA5w4Mn2RB4BvC5oa2cDxnq8oWqWgFcPbYCyiC8fraq7gVuSvJNYFfgdmBRVS1vY/8AOHeopt3b48cC/9oC7nrADa39QuCDbZ/uGVV1Y6vpyQwC9Z5V9dMp5moP4MCxJ1V1yyT7U2uyAarqxHYtdt52q0n7SZIkzQYPRlgNsG9VXXufxuTpwN1DTSuGnq8Yqu1kYJ+qWprkUGC3ceOvA9zaVjMnMnyNjPu9qv6T1fQR4INVdVaS3YB3A1TVMUm+ArwQ+G6SPVr/5QxC+s4MVpwnE1YOojcyCMdjHruKMSRJktYYD8ZXV50DHDm2Qphk59U8fyNgeZJ1gZU+rFVVtwM3JNm/jZ8kO61izAuAA5LMSbI58CzgktWo6RHAT9rjV401JplfVcuq6lhgMfCkduhW4E+BD7RwO5lzgSOGxtukrfLekeQP2xweAnxxNWqVJEmatR6MsPpeYF3giiRXtuer453AxcBXge9N0udg4LAkS4GrgL1XMeaZwBXAUgb7Qt9SVf+9GjW9m8G2g28Bvxhqf1P70NZSBvtV/2PsQFXdBLwY+FhbVZ7I+4BNhsYY23bwFwz2zF4H/GB4XEmSpDVZBh8w15po5223qvM//D9HXYYkSRPaeK8jV91Ja40kS6pql/Ht/gUrSZIkdevB+ICVxkny5wy+HmvYhVX1hlHUI0mS1CvD6ghU1UnASaOuQ5IkqXduA5AkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1a1phNckbkzw8A/+U5NIke850cZIkSVq7TXdl9dVVdTuwJ7A58OfAMTNWlSRJksT0w2ra7xcCJ1XV0qE2SZIkaUbMnWa/JUnOBbYGjk6yEbBi5srSA2HOwx/FxnsdOeoyJEmS7rfphtXDgAXA9VV1V5JNGWwFkCRJkmbMdLcB/BFwbVXdmuTPgHcAt81cWZIkSdL0w+oJwF1JdgLeAvwI+MyMVSVJkiQx/bB6T1UVsDfwoar6ELDRzJUlSZIkTX/P6h1Jjgb+DHhWkjnAujNXliRJkjT9ldUDgLuBw6rqv4HHAMfPWFWSJEkS01xZbQH1g0PP/wv3rEqSJGmGTffPrf5hkkVJ7kzymyT3JvHbACRJkjSjprsN4KPAQcD3gYcC/wP42EwVJUmSJMH0P2BFVV2XZE5V3QuclOQ7M1iXJEmSNO2weleS9YDLkxwHLAc2mLmyJEmSpOlvA3glMAc4Avgl8Dhg35kqSpIkSYLpfxvAj9rDXwHvmblyJEmSpN+ZMqwmWQbUZMerascHvCJJkiSpWdXK6suALYAfj2t/PPDTGalIkiRJalYVVv8eeNvQNgAAkmzejr14pgrT7+/nd9/MP37/tFGXIUmSZqnXbnPgqEtY5Qes5lXVFeMbq2oxMG9GKpIkSZKaVYXV9ac49tAHshBJkiRpvFWF1UVJXjO+MclhwJKZKUmSJEkaWNWe1TcBZyY5mN+F012A9YCXzmBdkiRJ0tRhtapuAp6RZHdg+9b8lar6+oxXJkmSpLXedP8owPnA+TNciyRJknQf0/1zq5IkSdKDzrAqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd1aq8Jqkt2SfHkE1z00yUd/zzH2SnJtkuuSvPWBqk2SJKlna1VYna2SzAE+BrwA2A44KMl2o61KkiRp5s26sJpkXpLvJflUkiuTnJpkjyQXJvl+koXt5ztJLmu/nzjBOBsk+XSSRa3f3q390CRfSPKlJDckOSLJX7U+302yaev3mnbu0iSfT/Kw1r5/q2tpkgsmuO6fJrkoyWaTvL4tkpzZzl+a5BnAQuC6qrq+qn4DnAbsPcn5hydZnGTxnTffcX+nWZIkqQuzLqw2fwB8CNgReBLwCuCZwFHA24DvAc+qqp2BdwEfmGCMtwNfr6pdgd2B45Ns0I5t38ZcCLwfuKuNdRFwSOtzRlXtWlU7AdcAh7X2dwHPb+0vGb5gkpcCbwVeWFW/mOS1fRj4Zjv/qcBVwGOAHw/1ubG1raSqTqyqXapqlw033WiSS0iSJM0Oc0ddwP10Q1UtA0hyFXBeVVWSZcA84BHAKUm2AQpYd4Ix9gRekuSo9nx9YKv2+PyqugO4I8ltwJda+zIGARlg+yTvAzYGNgTOae0XAicnOR04Y+h6uwO7AHtW1e1TvLbn0AJxVd0L3JYkE/SrKcaQJElaI8zWldW7hx6vGHq+gkEAfy+DwLk98GIGQXS8APtW1YL2s1VVXTPN8QFOBo6oqh2A94xdo6peB7wDeBxweZJHtv7XAxsB267+y+XGNt6YxwI/vR/jSJIkzSqzNayuyiOAn7THh07S5xzgyLFVyyQ7r+Y1NgKWJ1kXOHisMcn8qrq4qt4F/ILfhcwfAS8DPpPkKVOMex7wF22sOUkeDiwCtkmydZL1gAOBs1azXkmSpFlnTQ2rxwF/k+RCYM4kfd7LYHvAFUmubM9XxzuBi4GvMtgjO+b4JMvamBcAS8cOVNW1DILt55LMn2TcNwK7ty0NS4CnVNU9wBEMAvY1wOlVddVq1itJkjTrpMqtj2uqx+/whHrbGRN9tkySJGnVXrvNgQ/atZIsqapdxrevqSurkiRJWgPM1m8DmPWSvB3Yf1zz56rq/aOoR5IkqUeG1RFpodRgKkmSNAW3AUiSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6tbcURegmbP5QzbltdscOOoyJEmS7jdXViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHVr7qgL0MxZccst3Plv/zrqMiRJmtCG+x0w6hI0C7iyKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6pZhVZIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6tasDqtJdkvy5VHXMR1J7vw9z980yVeTfL/93uSBqk2SJKlXszqsrmXeCpxXVdsA57XnkiRJa7SRh9Uk85J8L8mnklyZ5NQkeyS5sK0iLmw/30lyWfv9xAnG2SDJp5Msav32bu2HJjkjydltvOOGzjkoybJ23WOH2u9McmySJUm+1q7/jSTXJ3nJUN3fSnJp+3lGa98yyQVJLm/j/sm4OjdLclGSP51iTt7S6lqa5JjWvDdwSnt8CrDP/ZpwSZKkWWTuqAto/gDYHzgcWAS8Angm8BLgbcAhwLOq6p4kewAfAPYdN8bbga9X1auTbAxckuRr7dgCYGfgbuDaJB8B7gWOBZ4G3AKcm2SfqvoCsAHwjar66yRnAu8DngdsxyAongX8DHheVf06yTbAZ4FdWu3nVNX7k8wBHjZWYJIt2rnvqKqvTjQRSV7AIIg+varuSrJpO7RFVS0HqKrlSR41yfmHt3nkcZttNlEXSZKkWaOXsHpDVS0DSHIVg7e7K8kyYB7wCOCUFgoLWHeCMfYEXpLkqPZ8fWCr9vi8qrqtjX818HjgkQwC6c9b+6nAs4AvAL8Bzm7nLgPurqrfDtVDq+GjSRYwCL7btvZFwKeTrAt8oaouH+p/HvCGqvrmFHOxB3BSVd0FUFU3T9F3JVV1InAiwFPnz6/VOVeSJKk3I98G0Nw99HjF0PMVDAL1e4Hzq2p74MUMguh4AfatqgXtZ6uqumaC8e9tY2aKen5bVWNB7//XU1Vj9QC8GbgJ2InBiup6rc8FDELvT4B/TnJI638PsAR4/hTXHXsdE4XMm5JsCYOtBgxWdiVJktZovYTVVXkEg/AHcOgkfc4BjkwSgCQ7r2LMi4Fntz2kc4CDgKlWPCeqaXkLsK8E5rTrPh74WVV9Evgn4KmtfwGvBp6UZKoPR50LvDrJw9p4Y9sAzgJe1R6/CvjiatQqSZI0K82WsHoc8DdJLqSFwgm8l8Fb7VckubI9n1Tb/3k0cD6wFLi0qlYnAH4ceFWS7zLYAvDL1r4bcHmSyxjsq/3Q0DXvBQ4Edk/y+knqOptBMF2c5HJgbFvDMcDzknyfwf7ZYyY6X5IkaU2S373brTXNU+fPrwuO/cCoy5AkaUIb7nfAqEtQR5IsqapdxrfPlpVVSZIkrYV6+TaAtU6SHYB/Htd8d1U9fRT1SJIk9ciwOiLtq7oWjLoOSZKknrkNQJIkSd0yrEqSJKlbhlVJkiR1y7AqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndMqxKkiSpW4ZVSZIkdcuwKkmSpG4ZViVJktQtw6okSZK6ZViVJElStwyrkiRJ6tbcURegmbPOJpuw4X4HjLoMSZKk+82VVUmSJHXLsCpJkqRuGVYlSZLULcOqJEmSumVYlSRJUrcMq5IkSeqWYVWSJEndSlWNugbNkCR3ANeOuo5ZYjPgF6MuYhZwnqbPuZo+52r6nKvpc66mr5e5enxVbT6+0T8KsGa7tqp2GXURs0GSxc7VqjlP0+dcTZ9zNX3O1fQ5V9PX+1y5DUCSJEndMqxKkiSpW4bVNduJoy5gFnGupsd5mj7navqcq+lzrqbPuZq+rufKD1hJkiSpW66sSpIkqVuG1TVQkr2SXJvkuiRvHXU9vUnywyTLklyeZHFr2zTJV5N8v/3eZNR1jkKSTyf5WZIrh9omnZskR7f77Nokzx9N1aMxyVy9O8lP2r11eZIXDh1bK+cqyeOSnJ/kmiRXJXlja/e+GmeKufK+GifJ+kkuSbK0zdV7Wrv31ThTzNWsua/cBrCGSTIH+E/gecCNwCLgoKq6eqSFdSTJD4FdquoXQ23HATdX1TEt4G9SVX89qhpHJcmzgDuBz1TV9q1twrlJsh3wWWAh8Gjga8C2VXXviMp/UE0yV+8G7qyqvx3Xd62dqyRbAltW1aVJNgKWAPsAh+J9dR9TzNXL8b66jyQBNqiqO5OsC3wbeCPwMryv7mOKudqLWXJfubK65lkIXFdV11fVb4DTgL1HXNNssDdwSnt8CoN/INY6VXUBcPO45snmZm/gtKq6u6puAK5jcP+tFSaZq8mstXNVVcur6tL2+A7gGuAxeF+tZIq5mszaPFdVVXe2p+u2n8L7aiVTzNVkupsrw+qa5zHAj4ee38jU/7NbGxVwbpIlSQ5vbVtU1XIY/IMBPGpk1fVnsrnxXpvYEUmuaNsExt6CdK6AJPOAnYGL8b6a0ri5Au+rlSSZk+Ry4GfAV6vK+2oSk8wVzJL7yrC65skEbe71uK8/rqqnAi8A3tDeztXq815b2QnAfGABsBz4u9a+1s9Vkg2BzwNvqqrbp+o6QdvaPlfeVxOoqnuragHwWGBhku2n6O5crTxXs+a+MqyueW4EHjf0/LHAT0dUS5eq6qft98+AMxm8vXFT2y82tm/sZ6OrsDuTzY332jhVdVP7R2EF8El+99bZWj1XbZ/c54FTq+qM1ux9NYGJ5sr7ampVdSvwDQZ7ML2vpjA8V7PpvjKsrnkWAdsk2TrJesCBwFkjrqkbSTZoH1wgyQbAnsCVDOboVa3bq4AvjqbCLk02N2cBByZ5SJKtgW2AS0ZQXzfG/pFsXsrg3oK1eK7ahzv+Cbimqj44dMj7apzJ5sr7amVJNk+ycXv8UGAP4Ht4X61ksrmaTffV3FFeXA+8qronyRHAOcAc4NNVddWIy+rJFsCZg38TmAv8S1WdnWQRcHqSw4D/AvYfYY0jk+SzwG7AZkluBP4XcAwTzE1VXZXkdOBq4B7gDWvDJ2vHTDJXuyVZwOAtsx8Cr4W1fq7+GHglsKztmQN4G95XE5lsrg7yvlrJlsAp7Rtw1gFOr6ovJ7kI76vxJpurf54t95VfXSVJkqRuuQ1AkiRJ3TKsSpIkqVuGVUmSJHXLsCpJkqRuGVYlSZLULcOqJD3IklSSvxt6flSSdz9AY5+cZL8HYqxVXGf/JNckOX9c+zpJPpzkyiTLkixq39U4k7X8MMlmM3kNSaNjWJWkB9/dwMt6C1jtexin6zDg9VW1+7j2A4BHAztW1Q4Mvmz81gemQklrI8OqJD347gFOBN48/sD4ldEkd7bfuyX5ZpLTk/xnkmOSHJzkkraCOX9omD2SfKv1e1E7f06S49tK5xVJXjs07vlJ/gVYNkE9B7Xxr0xybGt7F/BM4BNJjh93ypbA8vYnHKmqG6vqlnbeCUkWJ7kqyXuGrvHDJB9IclE7/tQk5yT5QZLXDdV5QZIzk1yd5BNJVvo3LMmftTm5PMk/ttc9p83r2GrvSvMuqV/+BStJGo2PAVckOW41ztkJeDJwM3A98KmqWpjkjcCRwJtav3nAs4H5wPlJ/gA4BLitqnZN8hDgwiTntv4Lge2r6obhiyV5NHAs8DTgFuDcJPtU1f9O8hzgqKpaPK7G04FvJ/kT4Dzg/1TVZe3Y26vq5raCe16SHavqinbsx1X1R0n+HjiZwV9zWh+4CvjEUJ3bAT8CzgZeBvzbUL1PZrCy+8dV9dskHwcObmM8pqq2b/02XuVMS+qGK6uSNAJVdTvwGeAvV+O0RVW1vKruBn4AjIXNZQwC6pjTq2pFVX2fQah9ErAncEj7M54XA49k8De/AS4ZH1SbXYFvVNXPq+oe4FTgWat4XTcCTwSOBlYwCKXPbYdfnuRS4DLgKQyC55izhl7LxVV1R1X9HPj1ULi8pKqub3/68bMMVneHPZdBsF7UXudzgSe0OXhCko8k2Qu4farXIKkvrqxK0uj8A3ApcNJQ2z20hYQkAdYbOnb30OMVQ89XcN//n4//O9oFBDiyqs4ZPpBkN+CXk9SXVdQ/oRam/wP4jyQ3AfskuR44Cti1qm5JcjKDldMxw69l/Osce20Tva7x9Z5SVUev9EKSnYDnA28AXg68enVfl6TRcGVVkkakqm5m8Lb5YUPNP2SwOgiwN7Du/Rh6//ap/PkMVhavBc4B/iLJugBJtk2ywSrGuRh4dpLN2lv3BwHfnOqEtt/00e3xOsCODN62fziDUHxbki2AF9yP17UwydZt3AOAb487fh6wX5JHtetvmuTx7YNs61TV54F3Ak+9H9eWNCKurErSaP0dcMTQ808CX0xyCYPwNdmq51SuZRAqtwBeV1W/TvIpBlsFLm0rtj8H9plqkKpanuRo4HwGq5b/XlVfXMW1HwV8su2LBbgE+Gir4TIG+0evBy68H6/rIuAYYAfgAuDMcfVeneQdDPbWrgP8lsFK6q+Ak4Y+kLXSyqukfqVq/LsokiT1pW1XOKqqXjTiUiQ9yNwGIEmSpG65sipJkqRuubIqSZKkbhlWJUmS1C3DqiRJkrplWJUkSVK3DKuSJEnqlmFVkiRJ3fp/qKhFF4XdkJsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette = 'pastel')\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saved Plots as JPG Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the image\n",
    "sns_plot.figure.savefig('barchart_cd.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repositories as CSV Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Numpy data frame is converted to a csv file.\n",
    "\n",
    " - Original repository of images resized and flattened saved as 'originalrepo.csv'\n",
    " - Binarised repository of images resized, binarised and flattened  saved as 'binarisedrepo.csv'\n",
    " - Hog feature extraction repository of images resized, binarised, hog features extracted and flattened saved as 'hogrepo.csv'\n",
    " - Class Decomposition repository of images resized, binarised, hog features extracted and flattened with class decomposition applied and flattened. Then saved as 'original_cd.csv'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " originalrepo saved as originalrepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('originalrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(originalrepo):\n",
    "        row = np.concatenate((h,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "\n",
    "print('\\n originalrepo saved as originalrepo.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoised Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " denoiserepo saved as denoiserepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('denoiserepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, l in enumerate(denoiserepo):\n",
    "        row = np.concatenate((l,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "print('\\n denoiserepo saved as denoiserepo.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hog Features Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " hogrepo saved as hogrepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('hogrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(hogrepo):\n",
    "        row = np.concatenate((h,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "\n",
    "print('\\n hogrepo saved as hogrepo.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarised Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " binarisedrepo saved as binarisedrepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('binarisedrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, l in enumerate(binarisedrepo):\n",
    "        row = np.concatenate((l,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "print('\\n binarisedrepo saved as binarisedrepo.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hog_ros saved as hog_ros.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('hog_ros.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(hogrepo_ros):\n",
    "        row = np.concatenate((h,[target_ros[i]]))\n",
    "        filewriter.writerow(row)\n",
    "        \n",
    "print('\\nhog_ros saved as hog_ros.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Decomposition Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " original_cd saved as original_cd.csv\n"
     ]
    }
   ],
   "source": [
    "   with open('original_cd.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, pix in enumerate(originalrepo):\n",
    "        row = np.concatenate((pix,[target_cd[i]]))\n",
    "        filewriter.writerow(row)\n",
    "        \n",
    "print('\\n original_cd saved as original_cd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implementation of a validation framework where the student compares the performance between the\n",
    "generated data sets and different classification algorithms (e.g. Support Vector Machine, Random Forests,\n",
    "Neural Networks, Convolutional Neural Networks, etc.). The student must discuss the metrics to be used (e.g.\n",
    "accuracy, precision, recall, etc.) and the experimental setting (simple split, cross-validation, leave-one-out,\n",
    "etc.).\n",
    "\n",
    "The student explained\n",
    "and justified the\n",
    "experimental setting in\n",
    "quality close to a\n",
    "scientific paper.\n",
    "A wide variety of\n",
    "classification algorithms\n",
    "and parameter settings\n",
    "are implemented with\n",
    "optimal code, showing a\n",
    "deep understanding of\n",
    "machine learning by\n",
    "explaining and justifying\n",
    "the methods and\n",
    "parameters.\n",
    "Results are presented in\n",
    "quality close to a\n",
    "scientific paper, using\n",
    "the most proper metrics\n",
    "and visualisation\n",
    "resources for the given\n",
    "scenario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there has been 5 datasets created. To evaluate datasets on their accuracy to classify female and males with masks and no mask. Each dataset will be split into a train and test set.The data will be split with 80% of the data kept for training the model and 20% used to test the model. Where then 3 algorithms such as Support Vectore Machine Classifier, Random Forest Classifier, Neural Network and Convolutional Neural Networks will be applied to all five repositories and stuctured such as:\n",
    "\n",
    "3.1 Original Repository \n",
    " - 3.1.1 Support Vectore Machine\n",
    " - 3.1.2 Random Forest Classifier\n",
    " - 3.1.3 Neural Network\n",
    " - 3.1.4 Convolutional Neural Networks\n",
    "  \n",
    "3.2 Binarised Repository \n",
    " - 3.2.1 Support Vectore Machine\n",
    " - 3.2.2 Random Forest Classifier\n",
    " - 3.2.3 Neural Network\n",
    " - 3.2.4 Convolutional Neural Networks\n",
    "\n",
    "3.3 Hog Repository \n",
    " - 3.3.1 Support Vectore Machine\n",
    " - 3.3.2 Random Forest Classifier\n",
    " - 3.3.3 Neural Network\n",
    " - 3.3.4 Convolutional Neural Networks\n",
    "\n",
    "3.4 ROS Repository\n",
    " - 3.4.1 Support Vectore Machine\n",
    " - 3.4.2 Random Forest Classifier\n",
    " - 3.4.3 Neural Network\n",
    " - 3.4.4 Convolutional Neural Networks\n",
    "\n",
    "3.5 Class Decomposition Repository \n",
    " - 3.5.1 Support Vectore Machine\n",
    " - 3.5.2 Random Forest Classifier\n",
    " - 3.5.3 Neural Network\n",
    " - 3.5.4 Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each repository, Support Vector Machine and Random Forest will be applied to the dataset before a cross validation function measures the accuracy of each classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scitkitlearns train_test_split function will allow the data to be split 80% of data into the training set and 20% split into a testing set. This will be stratified to provide an optimum split. Both classifiers are fit to their model with the training dataset before making the prediction model using the test set in each case respectively. This is shown below in section 1.1 and 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "target = np.array(target)\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(originalrepo, target, stratify=target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for SVM:  0.5592465647676393\n",
      "Mean Accuracy for RF:  0.5317153002933457\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, originalrepo, target, cv=5, scoring = 'accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Support Vector Machine is 56%. This is an improvement on the the 25% chance without a classifier. The number of true positives in the 101 which is higher than 83 number of true negatives. However there is more false positive than false negatives. This suggest the classifier is 53% more likely to identify the correct class than not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When true positive + false positive == 0, precision returns 0 and raises UndefinedMetricWarning. This behavior can be modified with zero_division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "#           'precision' : make_scorer(precision_score)}\n",
    "\n",
    "#precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run a neural network on the dataset these five steps are applied:\n",
    "    \n",
    " 1. Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
    " 2. One-Hot Encode the categorical column\n",
    " 3. Build a model architecture (Sequential) with Dense layers\n",
    " 4. Train the model and make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement one hot encoding the number of classes and the label of the classes to set each convert them to numerical values to be apply to train input into the neural network. The shape of the dataset and the target set can be checked to ensure it has the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Keras backend environment for CNN\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert target dataset to a numpy array for the NN\n",
    "target = np.array(target)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 4\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask\", \"femalenomask\", \"malemask\", \"malenomask\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels = np.zeros((len(target), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273, 10000) (1273, 4) (1273, 10000) (1273, 4)\n"
     ]
    }
   ],
   "source": [
    "print(originalrepo.shape, ohe_labels.shape, originalrepo.shape, ohe_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 2s 4ms/step - loss: 16.6716 - accuracy: 0.2307\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3854 - accuracy: 0.2689\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3856 - accuracy: 0.2658\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3822 - accuracy: 0.2815\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3809 - accuracy: 0.2814\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3810 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.3810449838638306; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 2s 4ms/step - loss: 26.5383 - accuracy: 0.2756\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3847 - accuracy: 0.2761\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3841 - accuracy: 0.2740\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3801 - accuracy: 0.2950\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3805 - accuracy: 0.2784\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3810569047927856; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 2s 4ms/step - loss: 125.5115 - accuracy: 0.3036\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3839 - accuracy: 0.2753\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3818 - accuracy: 0.2961\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3823 - accuracy: 0.2676\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3818 - accuracy: 0.2763\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.3812 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.3811827898025513; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 2s 4ms/step - loss: 71.3340 - accuracy: 0.2465\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3860 - accuracy: 0.2628\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3814 - accuracy: 0.3011\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3807 - accuracy: 0.2892\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3784 - accuracy: 0.3053\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1.3814 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.381369948387146; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 2s 3ms/step - loss: 50.6149 - accuracy: 0.2613\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3846 - accuracy: 0.2856\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3825 - accuracy: 0.2523\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 1.3836 - accuracy: 0.2651\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 1.3810 - accuracy: 0.2847\n",
      "8/8 [==============================] - 1s 3ms/step - loss: 1.3814 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.381407380104065; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_nn = []\n",
    "loss_per_fold_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "data = originalrepo\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of this neural network only has a 33% accuracy of predicting the correct classifier. This is very low accuracy however it is still an improvement compared to the 25% chance without using any classify. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN can classify and extract their own features therefore there is no need to use the hog dataset. This is why CNN will be used on the image repository. Thesefore the data will be split again using the datarepo and the target_cd.\n",
    "The images are all 100 by 100 images coloured imaged. The CNN will compute 32 filters over the input with a response map that is 26 x 26 in size. The siz of the patches is 3 x 3 and the depth of the output feature map is 32. Max pooling extracts windows from the input much like a convolution and halves the feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu function is a linear function but before the activation point gives you zero.  \n",
    "\n",
    "fully connected NN is when all inputs are connected to  all neurons in the first hidden layer. \n",
    "Then all neurons connect to a single neuron(second hidden layer) which produces the output.\n",
    " \n",
    "A logistic regression calculates the probability of an input to be 0 or 1 \n",
    "\n",
    "since we need to predict the probabiliry of a sample being 0 or 1 we need to set the activation function for th epredicted output to something more suitable\n",
    "relu can give 0 or 1 \n",
    "sigmoid function is most popular \n",
    "\n",
    "loss function\n",
    "you want to produce an expected output relevant output\n",
    "the initial hyptheses \n",
    "helps you find how far you are from the actual values\n",
    "\n",
    "the mathematical functio nhehind loss function wants the smallests value possible.\n",
    "\n",
    "cost function helps calculates the weights and the bias. the more training data you have you can average more when you calculate your loss\n",
    "the cost function depends on the training function\n",
    "\n",
    "gradient descent \n",
    "you want to find wight and ias that minisiase the cost\n",
    "you get a 3d function valuing your cost\n",
    "\n",
    "alpha is the learning rate gives a difference neature when you train the neural network\n",
    "\n",
    "\n",
    "when you calculate and you update the weight bias it is referred to as back propagation \n",
    "you need to pass the image through the network and pass it back \n",
    "you pass a batch of data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to train the model. We will define a sequential CNN with two convolutional layers, a max pooling of size 2×2 and a dropout of 0.25. Then, we will add a flatten layer, add a densely connected layer with a ReLu activation, afterwards add another dropout of 0.5, and finally add a densely connected layer to the output with a softmax activation function. This configuration is not strict and you can find many different examples, such as this other one. NOTE: If you get an error, you may need to change the input_shape to (1,28,28), which means that you also need to change the shape of X_train_reshape and X_test_reshape to (X.shape[0],1,28,28).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data into four dimensions i.e. the training set will be of shape (60000,28,28,1) and the test set of (10000,28,28). This is useful since the network needs an input shape of (1,28,28) for each of the samples.\n",
    "\n",
    "Convert the format of the input into float32 (apparently the CNN works better with it).\n",
    "\n",
    "Normalise i.e. divide all values by 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be transformed from standard to normalised grayscale by dividing the numpyarray by 255 before reducing noise to help improve the image for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs also like their target to be categorical, i.e. instead of the target being values from 0 to 9, each target value will be a vector indicating which is the class according to the position. Run the following cell to see what I mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the model architecture, we will compile it. We will use the adam optimiser to improve the loss obtained by the cross_entropy method, and then we will request the model to obtain the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once compiled, we will fit this model using our training data. If your computer is slow, I recommend you NOT to use the entire training dataset. This can be done by reducing the number n to something smaller than 60'000. Also, you can reduce the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 132ms/step - loss: 1.6091 - accuracy: 0.3198\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.0665 - accuracy: 0.5628\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 0.8715 - accuracy: 0.6629\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 0.5216 - accuracy: 0.8166\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 0.3413 - accuracy: 0.8802\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.3663 - accuracy: 0.5490\n",
      "Score for fold 1: loss of 1.3663049936294556; accuracy of 54.90196347236633%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.5409 - accuracy: 0.3528\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 27s 133ms/step - loss: 1.1989 - accuracy: 0.4771\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 27s 132ms/step - loss: 0.8831 - accuracy: 0.6592\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 27s 133ms/step - loss: 0.5608 - accuracy: 0.7875\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 140ms/step - loss: 0.3239 - accuracy: 0.8893\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.3410 - accuracy: 0.5882\n",
      "Score for fold 2: loss of 1.340988039970398; accuracy of 58.82353186607361%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 139ms/step - loss: 1.4877 - accuracy: 0.3243\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 1.0373 - accuracy: 0.5771\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 0.7803 - accuracy: 0.7032\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.4329 - accuracy: 0.8350\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 0.2791 - accuracy: 0.9059\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.5488 - accuracy: 0.5725\n",
      "Score for fold 3: loss of 1.5488176345825195; accuracy of 57.2549045085907%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 142ms/step - loss: 1.4061 - accuracy: 0.3449\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 0.9228 - accuracy: 0.6554\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 0.6402 - accuracy: 0.7584\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 149ms/step - loss: 0.3965 - accuracy: 0.8573\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 0.2102 - accuracy: 0.9286\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.4382 - accuracy: 0.5984\n",
      "Score for fold 4: loss of 1.4381864070892334; accuracy of 59.84252095222473%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 144ms/step - loss: 1.4517 - accuracy: 0.3429\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 1.0042 - accuracy: 0.6248\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 0.6935 - accuracy: 0.7571\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 145ms/step - loss: 0.3726 - accuracy: 0.8631\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.2230 - accuracy: 0.9260\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.1240 - accuracy: 0.6024\n",
      "Score for fold 5: loss of 1.1240322589874268; accuracy of 60.23622155189514%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_cnn = []\n",
    "loss_per_fold_cnn = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "data = originalrepo\n",
    "fold_no = 1\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "\n",
    "    \n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the models objectively cross validation will be implemented. By importing the cross_validate function from sklearn.model_selection the accuracy scores of support vector machine and random forest will be compared. \n",
    "\n",
    "Evaluating Precision, Recall and F1-score both by fold and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoised Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(denoiserepo, target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be applied to Support Vector Machine algorithm below with the Support Vector Classifier(SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for SVM:  0.5529689671144048\n",
      "Mean Accuracy for RF:  0.5348926972363749\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, denoiserepo, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, denoiserepo, target, cv=5, scoring = 'accuracy')))\n",
    "#precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Support Vector Machine is 64%. This is an improvement on the the 25% chance without a classifier. The number of true positives in the 101 which is higher than 83 number of true negatives. However there is more false positive than false negatives. This suggest the classifier is 64% more likely to identify the correct class than not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network will be implemented following the 4 steps previously found in section 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4502 - accuracy: 0.2734\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3808 - accuracy: 0.3429\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3682 - accuracy: 0.3077\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3630 - accuracy: 0.3008\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3168 - accuracy: 0.3420\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3035 - accuracy: 0.3647\n",
      "Score for fold 1: loss of 1.3035420179367065; accuracy of 36.4705890417099%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4102 - accuracy: 0.2354\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3841 - accuracy: 0.2700\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.2817\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3852 - accuracy: 0.2640\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3813 - accuracy: 0.2873\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3811193704605103; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4731 - accuracy: 0.2578\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3853 - accuracy: 0.2628: 0s - loss: 1.3860 - ac\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3866 - accuracy: 0.2456\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3822 - accuracy: 0.2738\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3858 - accuracy: 0.2698\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3812 - accuracy: 0.2745\n",
      "Score for fold 3: loss of 1.3812451362609863; accuracy of 27.450981736183167%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4394 - accuracy: 0.2466\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.2875\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3809 - accuracy: 0.2841\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3806 - accuracy: 0.2762\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3815 - accuracy: 0.2666\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3813 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.3812921047210693; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4708 - accuracy: 0.2475\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3853 - accuracy: 0.2759\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3844 - accuracy: 0.2591\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3802 - accuracy: 0.2760\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3828 - accuracy: 0.2750\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.3813875913619995; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "data = denoiserepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_de_nn = []\n",
    "loss_per_fold_de_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_de_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_de_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN can classify and extract their own features therefore there is no need to use the hog dataset. This is why CNN will be used on the image repository. Thesefore the data will be split again using the datarepo and the target_cd.\n",
    "The images are all 100 by 100 images coloured imaged. The CNN will compute 32 filters over the input with a response map that is 26 x 26 in size. The siz of the patches is 3 x 3 and the depth of the output feature map is 32. Max pooling extracts windows from the input much like a convolution and halves the feature map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 138ms/step - loss: 1.3897 - accuracy: 0.2338\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3837 - accuracy: 0.2390\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 1.3802 - accuracy: 0.2836\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 148ms/step - loss: 1.3794 - accuracy: 0.2734\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 1.3776 - accuracy: 0.2991\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.3807 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.3807481527328491; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3877 - accuracy: 0.2793\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3830 - accuracy: 0.2854\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 1.3829 - accuracy: 0.2884\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 1.3838 - accuracy: 0.2396\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 30s 147ms/step - loss: 1.3818 - accuracy: 0.2448\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.3808 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3807686567306519; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 144ms/step - loss: 1.3889 - accuracy: 0.2563\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 1.3834 - accuracy: 0.2681\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 1.3803 - accuracy: 0.2768\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 145ms/step - loss: 1.3816 - accuracy: 0.2795\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 1.3760 - accuracy: 0.3205\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 1.3808 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.380800724029541; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3874 - accuracy: 0.2535\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 1.3851 - accuracy: 0.2609\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3818 - accuracy: 0.2699\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 1.3843 - accuracy: 0.2610\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 1.3834 - accuracy: 0.2926\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.3810 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.3810144662857056; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 31s 147ms/step - loss: 1.3876 - accuracy: 0.2785\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 30s 147ms/step - loss: 1.3830 - accuracy: 0.3024\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 30s 145ms/step - loss: 1.3779 - accuracy: 0.3006\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 149ms/step - loss: 1.3827 - accuracy: 0.2603\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 30s 146ms/step - loss: 1.3832 - accuracy: 0.2485\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.3811 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.3811417818069458; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = denoiserepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_de_cnn = []\n",
    "loss_per_fold_de_cnn = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    \n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_de_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_de_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the models objectively cross validation will be implemented. By importing the cross_validate function from sklearn.model_selection the accuracy scores of support vector machine and random forest will be compared. \n",
    "\n",
    "Evaluating Precision, Recall and F1-score both by fold and average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarised Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(binarisedrepo, target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# Fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3859 - accuracy: 0.2455\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.2294\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3812 - accuracy: 0.2794\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.2806\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3794 - accuracy: 0.3099\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.3811358213424683; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3862 - accuracy: 0.2487\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3856 - accuracy: 0.2588\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3820 - accuracy: 0.2747\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.2430\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3812 - accuracy: 0.2871\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3810597658157349; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3854 - accuracy: 0.2767\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3842 - accuracy: 0.2842\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3819 - accuracy: 0.3047\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3805 - accuracy: 0.2788\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.2844\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.3810985088348389; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3858 - accuracy: 0.2479\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3827 - accuracy: 0.2820\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3829 - accuracy: 0.2811\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.2434\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3801 - accuracy: 0.2715\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.381362795829773; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3860 - accuracy: 0.2597\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3846 - accuracy: 0.2764\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3814 - accuracy: 0.2962\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.2463\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3807 - accuracy: 0.2737\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3813 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.381322979927063; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "data = binarisedrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_bin_nn = []\n",
    "loss_per_fold_bin_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_bin_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_bin_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN can classify and extract their own features therefore there is no need to use the hog dataset. This is why CNN will be used on the image repository. Thesefore the data will be split again using the datarepo and the target_cd.\n",
    "The images are all 100 by 100 images coloured imaged. The CNN will compute 32 filters over the input with a response map that is 26 x 26 in size. The siz of the patches is 3 x 3 and the depth of the output feature map is 32. Max pooling extracts windows from the input much like a convolution and halves the feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 133ms/step - loss: 1.3860 - accuracy: 0.2480\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 1.3845 - accuracy: 0.2809\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3812 - accuracy: 0.2664\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 1.3805 - accuracy: 0.2834\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3814 - accuracy: 0.2812\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.3812 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.3811935186386108; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 138ms/step - loss: 1.3854 - accuracy: 0.2447\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 1.3852 - accuracy: 0.2294\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 1.3812 - accuracy: 0.2953\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 147ms/step - loss: 1.3833 - accuracy: 0.2876\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3809 - accuracy: 0.2676\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.381096363067627; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 31s 148ms/step - loss: 1.3860 - accuracy: 0.2764\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.3851 - accuracy: 0.2703\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 31s 150ms/step - loss: 1.3793 - accuracy: 0.3006\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 1.3840 - accuracy: 0.2703\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 27s 134ms/step - loss: 1.3785 - accuracy: 0.2954\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.3811213970184326; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 139ms/step - loss: 1.3857 - accuracy: 0.2715\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3826 - accuracy: 0.3089\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.3827 - accuracy: 0.2777\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 27s 134ms/step - loss: 1.3822 - accuracy: 0.2646\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.3816 - accuracy: 0.2799\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 1.3813 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.3813151121139526; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3858 - accuracy: 0.2763\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3843 - accuracy: 0.2474\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.3823 - accuracy: 0.2836\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.3820 - accuracy: 0.2564\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.3826 - accuracy: 0.2900\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 1.3813 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.3813432455062866; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = binarisedrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_bin_cnn = []\n",
    "loss_per_fold_bin_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    \n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_bin_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_bin_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation will be implemented to compare the precision, recall and f1 score of each classifier on the binarised repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hog Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be applied to Support Vector Machine algorithm below with the Support Vector Classifier(SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hogrepo, target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hogrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_nn = []\n",
    "loss_per_fold_hog_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = hogrepo\n",
    "fold_no = 1\n",
    "\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_cnn = []\n",
    "loss_per_fold_hog_cnn = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "\n",
    "\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROS Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be applied to Support Vector Machine algorithm below with the Support Vector Classifier(SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hogrepo_ros, target_ros, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, originalrepo, target, cv=5, scoring = 'accuracy')))\n",
    "precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the Support Vector Machine is 64%. This is an improvement on the the 25% chance without a classifier. The number of true positives in the 101 which is higher than 83 number of true negatives. However there is more false positive than false negatives. This suggest the classifier is 64% more likely to identify the correct class than not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert target dataset to a numpy array for the NN\n",
    "target_ros = np.array(target_ros)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 4\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask_c0\", \"femalemask_c1\", \"femalenomask_c0\", \"malemask_c0\", \"malemask_c1\", \"malenomask_c0\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels_ros = np.zeros((len(target_ros), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target_ros)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target_ros[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels_ros[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hogrepo_ros\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_ros_nn = []\n",
    "loss_per_fold_hog_ros_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_ros.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_ros[train_index], ohe_labels_ros[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_ros_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_ros_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = hogrepo_ros\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_ros_cnn = []\n",
    "loss_per_fold_hog_ros_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_ros.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_ros[train_index], ohe_labels_ros[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    \n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_ros_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_ros_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Decomposition Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will be applied to Support Vector Machine algorithm below with the Support Vector Classifier(SVC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(originalrepo, target_cd, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating Mean Accuracy for all folds\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print('Mean Accuracy for SVM: ',np.mean(cross_val_score(svc_model, originalrepo, target_cd, cv=5, scoring = 'accuracy')))\n",
    "print('Mean Accuracy for RF: ',np.mean(cross_val_score(rf_model, originalrepo, target_cd, cv=5, scoring = 'accuracy')))\n",
    "precision_score(y_test, rf_pred, average='micro', zero_division=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert target dataset to a numpy array for the NN\n",
    "target_cd = np.array(target_cd)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 6\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask_c0\", \"femalemask_c1\", \"femalenomask_c0\", \"malemask_c0\", \"malemask_c1\", \"malenomask_c0\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels_cd = np.zeros((len(target_cd), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target_cd)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target_cd[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels_cd[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = originalrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_cd_nn = []\n",
    "loss_per_fold_cd_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_cd.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_cd[train_index], ohe_labels_cd[val_index]\n",
    "    \n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, we use a separate test data-set. As in the train data, the images in the test data also need to be reshaped before they can be provided to the fully-connected network because the network expects one column per pixel in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN can classify and extract their own features therefore there is no need to use the hog dataset. This is why CNN will be used on the image repository. Thesefore the data will be split again using the datarepo and the target_cd.\n",
    "The images are all 100 by 100 images coloured imaged. The CNN will compute 32 filters over the input with a response map that is 26 x 26 in size. The siz of the patches is 3 x 3 and the depth of the output feature map is 32. Max pooling extracts windows from the input much like a convolution and halves the feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = originalrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_cd_cnn = []\n",
    "loss_per_fold_cd_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_cd.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_cd[train_index], ohe_labels_cd[val_index]\n",
    "\n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    \n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_cd_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_cd_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train shape (988, 100, 100, 1)\n",
    "y_train shape (988, 4)\n",
    "X_test shape (248, 100, 100, 1)\n",
    "y_test shape (248, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Discussion of the results and \"future work\" (i.e. How to improve the obtained results?)\n",
    "\n",
    "\n",
    "The student reflected in\n",
    "a profound manner on\n",
    "the obtained results,\n",
    "showing an exceptional\n",
    "analysis methodology\n",
    "and understanding of\n",
    "the scenario.\n",
    "The student provided a\n",
    "set of clear guidelines\n",
    "that could potentially\n",
    "improve the work\n",
    "provided that more\n",
    "resources are allocated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model currently is in need of improved both with the data set and the pre processing. The data would benefit from even more images of female faces without masks as there is still a majority of male faces. The binarisation needs to be fixed and the feature extraction needs to adapt to recognise faces under masks. The feature extraction also needs to add the complexity of recognising gender before it can be properly evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

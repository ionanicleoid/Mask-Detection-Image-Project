{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will aim to create different models to for mask detection in images with the added complexity of determining gender whether are female or male. Pre-processing the images to resize, binarise and extracted features before performing image augmentation and class decomposition. Each dataset generated in the process is compared through the accuracy of multiple classifiers such as Support Vector Machine (SVM), Random Forest (RF), Neural Network(NN) and Convolutional Neural Network (CNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image repository initially consisted of the Gupta Human Faces (HF) dataset (2020). This data had sufficient data for masked individuals of both genders however it was lacking in the amount of unmasked faces. Especially unmasked females, which would be crucial for the model. Therefore, a second dataset The Larxel Face Mask Detection(FMD)(2020) was introduced extracting 250 images of female faces and 250 male faces without masks. Any images where masks were not properly on were deleted and group photos within the datasets were cropped to extract multiple faces from each photo.\n",
    "Resulting in 1273 images compiled for the experiments.\n",
    "\n",
    "Once the two datasets were collected, four subfolders were created. The images within them were manually divided to each subfolder depending on whether they were male or female or had a mask on and named below:\n",
    "\n",
    " - 'femalemask' – Contains female faces with a mask.\n",
    " - 'femalenomask' – Contains female faces without a mask.\n",
    " - 'malemask' – Contains male faces with a mask.\n",
    " - ‘malenomask' – Contains male faces without a mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three aims of the pre-processing stage:\n",
    "\n",
    " - Resize Images\n",
    " - Binarise Image \n",
    " - Histogram of Gradients(HOG) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Resize Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pre-processing stage, the images will be resized and then binarised. The images are loaded and resized to 100x100 so that all the images in the repository will be the same size for the classification problem further on. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. Binarise  Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is binarised and have a threshold added to the images. Creating a copy of the image, the function iterates over all rows and columns of the array, comparing the pixel value to the threshold. When the pixel's value is smaller than the threshold, it’s value is transformed to zero. If the value is greater than the threshold it is converted to 255. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Histogram of Gradients(HOG) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract facial features from the images to allow for the classification a technique HOG is applied to the image repository. Counting the number of times a gradient orientation appears in a specific area of an image to turn the image into a feature vector.  The image's x and y gradients, is determined with its magnitude by splitting the image into patches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.3.1 Creating the Hog Feature Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "# Obtaining the HOG gradients of an image\n",
    "from skimage import feature\n",
    "class HOG:\n",
    "    def __init__(self, orientations = 9, pixelsPerCell = (8, 8),\n",
    "        cellsPerBlock = (3, 3), transform = False):\n",
    "        # store the number of orientations, pixels per cell,\n",
    "        # cells per block, and whether or not power law\n",
    "        # compression should be applied\n",
    "        self.orienations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.transform = transform\n",
    "\n",
    "    def describe(self, image):\n",
    "        # compute HOG for the image\n",
    "        hist = feature.hog(image, orientations = self.orienations,\n",
    "            pixels_per_cell = self.pixelsPerCell,\n",
    "            cells_per_block = self.cellsPerBlock,\n",
    "            transform_sqrt = self.transform)\n",
    "        ## return the HOG features\n",
    "        return hist\n",
    "    \n",
    "hog = HOG(orientations = 18, pixelsPerCell = (10, 10), cellsPerBlock = (1, 1), transform = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Apply Pre-Processing to Image Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the relevant packages\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage import feature\n",
    "from pandas import DataFrame\n",
    "from skimage import morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#set the desired width and height\n",
    "resize_factor = 100 # applies for both height and width\n",
    "\n",
    "#set path to the images\n",
    "path = 'images'\n",
    "target =  []\n",
    "datarepo = [] # List to append the images as 2D numpy arrays\n",
    "originalrepo = [] # Create a repo for flattened pixels\n",
    "binarisedrepo = []  # Create a list to append the binarised pixels\n",
    "hogrepo = [] # Create a list to append the HOG features\n",
    "denoiserepo = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "     for file in files:\n",
    "        with open(os.path.join(root, file), \"r\") as auto:\n",
    "            if file != \".DS_Store\":\n",
    "                #pre-processing the data\n",
    "                #load each image\n",
    "                image = cv2.imread(root+'/'+file, 0)\n",
    "                 #resize each image\n",
    "                image = cv2.resize(image, (resize_factor, resize_factor))\n",
    "                #assign each image to datarepo\n",
    "                datarepo.append(image)\n",
    "                #flatten each image to origninaldata\n",
    "                originalrepo.append(image.flatten())\n",
    "                #binarise each image\n",
    "                _, image = cv2.threshold(image, 180, 255, 0)\n",
    "                #flatten binarised images\n",
    "                binarisedrepo.append(image.flatten())\n",
    "                # Extract HOG and append to HOG repo\n",
    "                hogfeatures = hog.describe(image)\n",
    "                hogrepo.append(hogfeatures)\n",
    "                 # Append the folder where the image is to the target list\n",
    "                target.append(root.replace(path,'').replace('\\\\','')) \n",
    "                \n",
    "                \n",
    "# Convert the repo list into  numpy arrays\n",
    "originalrepo = np.array(originalrepo) \n",
    "binarisedrepo = np.array(binarisedrepo)\n",
    "hogrepo = np.array(hogrepo)\n",
    "denoiserepo = np.array(denoiserepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Calculating Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Class  Number of Samples\n",
      "0    femalemask                348\n",
      "1  femalenomask                285\n",
      "2      malemask                355\n",
      "3    malenomask                285\n",
      "Total images: 1273\n"
     ]
    }
   ],
   "source": [
    "#relevant packages imported\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target)])\n",
    "\n",
    "# Load as a panda\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target)))\n",
    "\n",
    "#The results states that there is 348 instances of the class femalemask, 285 instances of the class femalenomask, \n",
    "#With 355 instances of the class malemask and 285 instances of the class malenomask.\n",
    "#Overall, the original repository contains 1273 images stored as a numpy array \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Visualise Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of target:  1273\n",
      "Size of original repository:  (1273, 10000)\n",
      "Example of original repository: \n",
      "[[222 221 221 ... 242 246 250]\n",
      " [ 40  34  34 ...   0   0   0]\n",
      " [230 228 228 ...  91 111 114]\n",
      " ...\n",
      " [124 124 123 ...  88  95 102]\n",
      " [117 117 118 ... 255 255 255]\n",
      " [145 133 127 ...  66  64  63]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette=\"Blues\")\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Size of target: ', len(target))\n",
    "print('Size of original repository: ', originalrepo.shape)\n",
    "print('Example of original repository: ')\n",
    "print(originalrepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot visualises how male mask has the most number of samples within the data frame with female masks being the second highest number of instances. With females without masks and males without masks with the next highest count repectively. This shows a class imbalance as there is more counts of images with masks than without mask and there is over double the number of males with masks than without.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Class Distribution Bar Chart\n"
     ]
    }
   ],
   "source": [
    "# Save the image\n",
    "sns_plot.figure.savefig('barchart.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n",
    "print('Saved Class Distribution Bar Chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of target:  1273\n",
      "Size of original repository:  (1273, 10000)\n",
      "Size of binarised data structure:  (1273, 10000)\n",
      "Size of HOG features data structure:  (1273, 1800)\n"
     ]
    }
   ],
   "source": [
    "print('Size of target: ', len(target))\n",
    "print('Size of original repository: ', originalrepo.shape)\n",
    "print('Size of binarised data structure: ', binarisedrepo.shape)\n",
    "print('Size of HOG features data structure: ', hogrepo.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1. Random OverSampling Repository "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random OverSampling (ROS) is a data-based imbalance handling techniques that is applied to the HOG repository. This aims to increase the minority class to provide a balanced dataset. There can be issues when using a non-binary dataset because it is more difficult to establish the minority class however the process is applied below, and this augmentation is visualised in the following bar plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.1 Calculate the Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating class distribution (after ROS)\n",
      "          Class  Number of Samples\n",
      "0    femalemask                355\n",
      "1  femalenomask                355\n",
      "2      malemask                355\n",
      "3    malenomask                355\n",
      "Total images: 1420\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "hogrepo_ros, target_ros = ros.fit_resample(hogrepo,target)\n",
    "\n",
    "print('\\nCalculating class distribution (after ROS)')\n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target_ros)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target_ros):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target_ros)])\n",
    "## Save the histogram as a .csv file   \n",
    "with open('classdistribution_ros.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, hist in enumerate(histo):\n",
    "        filewriter.writerow(hist)\n",
    "## Convert histo into a panda dataframe\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target_ros)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.2 Visualise Class Distribution After ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing class distribution bar chart (after ros)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ROS augmented target:  1420\n",
      "Size of ROS augmented repository:  (1420, 1800)\n",
      "The repository has been augmented from 1273 images with the size of 10000, to 1420 images with the size of 1800. \n",
      "Resulting in each class containing 350 instances each and more balanced.\n"
     ]
    }
   ],
   "source": [
    "## Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette=\"Set2\")\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "print('\\nShowing class distribution bar chart (after ros)')\n",
    "plt.show()\n",
    "\n",
    "print('Size of ROS augmented target: ', len(target_ros))\n",
    "print('Size of ROS augmented repository: ', hogrepo_ros.shape)\n",
    "print('The repository has been augmented from 1273 images with the size of 10000, to 1420 images with the size of 1800. \\nResulting in each class containing 350 instances each and more balanced.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the image\n",
    "sns_plot.figure.savefig('barchart_ros.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However random oversampling is most effective on binary classification, as this is a non-binary classification it is further improved with the application of class decomposition. The Standard Balancing Equation can help calculate the imbalances with the number of clusters representing the total number of instances of a specific class divided by the mean class distribution. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.3.2 K Using Standard Balancing Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of k for each class:  [2, 1, 2, 1]\n",
      "Number of classes after class decomposition:  6\n"
     ]
    }
   ],
   "source": [
    "#The function created below calculates k values for each class. \n",
    "#This will obtain the number of classes to determine a new class distribution to improve imbalance.\n",
    "def standardbalancingequation(target):\n",
    "    import math\n",
    "    \n",
    "    ## Obtain the number of classes in label list and sort\n",
    "    labelsIndexesUnique = list(set(target))\n",
    "    labelsIndexesUnique.sort()\n",
    "    \n",
    "    ## For each class, count the number of instances and calculate ki\n",
    "    k = []\n",
    "    for label in labelsIndexesUnique:\n",
    "        k.append(target.count(label))\n",
    "    avgInst = sum(k)/len(k)\n",
    "    k = [math.floor((ki/avgInst)+1) for ki in k]\n",
    "    print('Values of k for each class: ', k)\n",
    "    return k\n",
    "\n",
    "k_kmeans = standardbalancingequation(target)\n",
    "print('Number of classes after class decomposition: ', sum(k_kmeans))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.1. Class Decomposition(CD) Using KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters for class femalemask: 2\n",
      "Number of clusters for class femalenomask: 1\n",
      "Number of clusters for class malemask: 2\n",
      "Number of clusters for class malenomask: 1\n"
     ]
    }
   ],
   "source": [
    "def CDKmeans(data, target, k): \n",
    "    from sklearn.cluster import KMeans\n",
    "    target_cd = ['']*len(target)\n",
    "    IndexesUnique = list(set(target))\n",
    "    IndexesUnique.sort()\n",
    "    for i, label in enumerate(IndexesUnique):\n",
    "        print('Number of clusters for class '+str(label)+': '+str(k[i]))\n",
    "        \n",
    "        ## Split the dataset\n",
    "        data_tocluster = []\n",
    "        data_tocluster_index = []\n",
    "        for j, dat in enumerate(data):\n",
    "            if target[j]==label:\n",
    "                data_tocluster.append(dat)\n",
    "                data_tocluster_index.append(j)\n",
    "        if 1<k[i]<=len(data_tocluster):\n",
    "            \n",
    "                ## Apply k-means to the list    \n",
    "                kmeans = KMeans(n_clusters=k[i], random_state=0).fit(data_tocluster)\n",
    "                for n, m in enumerate(kmeans.labels_):\n",
    "                    target_cd[data_tocluster_index[n]]=str(label)+'_c'+str(m)\n",
    "        else:\n",
    "            for m in data_tocluster_index:\n",
    "                target_cd[m]=str(label)+'_c0'\n",
    "    return target_cd\n",
    "\n",
    "target_cd = CDKmeans(binarisedrepo, target, k_kmeans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the k value for femalenomask and malenomask is less than 2, no clustering is needed. However, femalemask and malemask all have values over 2 therefore floor is applied to give the correct clusters. This results in the creation of two new classes for femalemask and malemask which as femalemask_cd and malemask_cd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2. New Class Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Class  Number of Samples\n",
      "0    femalemask_c0                279\n",
      "1    femalemask_c1                 69\n",
      "2  femalenomask_c0                285\n",
      "3      malemask_c0                123\n",
      "4      malemask_c1                232\n",
      "5    malenomask_c0                285\n",
      "Total images: 1273\n",
      "The class decomposition method increased the size of the augmented pixel repository to 1236 rows with 1800 columns\n"
     ]
    }
   ],
   "source": [
    "#This is shown by calulating the new class distribution below. \n",
    "histo = [['Class','Number of Samples']]\n",
    "for i, label1 in enumerate(sorted(list(set(target_cd)))):\n",
    "    cont = 0\n",
    "    for j, label2 in enumerate(target_cd):\n",
    "        if label1 == label2:\n",
    "            cont+=1\n",
    "    histo.append([label1,cont])\n",
    "histo.append(['Total Samples', len(target_cd)])\n",
    "\n",
    "        \n",
    "## Convert histo into a panda dataframe\n",
    "histo_panda = pd.DataFrame.from_records(histo[1:-1], columns=histo[0])\n",
    "print(histo_panda)\n",
    "print('Total images: '+str(len(target_cd)))\n",
    "print('The class decomposition method increased the size of the augmented pixel repository to 1236 rows with 1800 columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target_cd consists of the 2 female mask classifiers, femalemask_c0 with 279 and femalemask_c1 with 69. A classifier for females without masks (femalenomask_c0 )with 285, a classifier for males without masks (malenomask_c0) with 285. With finally 2 male mask classifiers, malemask_c0 with 123 and malemask_c1 with 232. Overall creating six classes in this class decomposition target_cd and visualised below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.3. Visualise Class Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create a histogram using seaborn\n",
    "sns_plot = sns.barplot(y=\"Class\", x=\"Number of Samples\", data=histo_panda, palette = 'pastel')\n",
    "sns_plot.figure.set_size_inches(10,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the image\n",
    "sns_plot.figure.savefig('barchart_cd.jpg', orientation = 'landscape', dpi = 600, transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Repositories as CSV Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Numpy data frame is converted to a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.1. Original Repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original repository of images resized and flattened saved as originalrepo.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('originalrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(originalrepo):\n",
    "        row = np.concatenate((h,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "\n",
    "print('\\nOriginal repository of images resized and flattened saved as originalrepo.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.2. Binarised Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binarised repository of images resized, binarised and flattened  saved as binarisedrepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('binarisedrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, l in enumerate(binarisedrepo):\n",
    "        row = np.concatenate((l,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "print('\\nBinarised repository of images resized, binarised and flattened  saved as binarisedrepo.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.3. Hog Features Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hog feature extraction repository of images resized, binarised, hog features extracted and flattened saved as hogrepo.csv\n"
     ]
    }
   ],
   "source": [
    "with open('hogrepo.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(hogrepo):\n",
    "        row = np.concatenate((h,[target[i]]))\n",
    "        filewriter.writerow(row)\n",
    "\n",
    "print('\\nHog feature extraction repository of images resized, binarised, hog features extracted and flattened saved as hogrepo.csv')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.4. ROS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROS repository of images resized, binarised, hog features extracted with random oversampling applied and flattened. Then saved as hog_ros.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('hog_ros.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, h in enumerate(hogrepo_ros):\n",
    "        row = np.concatenate((h,[target_ros[i]]))\n",
    "        filewriter.writerow(row)\n",
    "        \n",
    "print('\\nROS repository of images resized, binarised, hog features extracted with random oversampling applied and flattened. Then saved as hog_ros.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.5. Class Decomposition Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class Decomposition repository of images resized, binarised, hog features extracted and with class decomposition applied and flattened. Then saved as original_cd.csv\n"
     ]
    }
   ],
   "source": [
    "   with open('original_cd.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    filewriter = csv.writer(csvfile, delimiter=',')\n",
    "    for i, pix in enumerate(originalrepo):\n",
    "        row = np.concatenate((pix,[target_cd[i]]))\n",
    "        filewriter.writerow(row)\n",
    "        \n",
    "print('\\n Class Decomposition repository of images resized, binarised, hog features extracted and with class decomposition applied and flattened. Then saved as original_cd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there has been 4 datasets created and a class decomposition target repository. To evaluate their accuracy to classify female and males with masks and no mask, each dataset will be split into a train and test set. The data will be split with 80% of the data kept for training the model and 20% used to test the model. Where then 4 classifiers such as Support Vectore Machine Classifier, Random Forest Classifier, Neural Network and Convolutional Neural Networks will be applied to all repositories. and stuctured such as: \n",
    " \n",
    "3.1 Original Repository  \n",
    " - 3.1.1 Support Vectore Machine \n",
    " - 3.1.2 Random Forest Classifier \n",
    " - 3.1.3 Neural Network \n",
    " - 3.1.4 Convolutional Neural Networks \n",
    "   \n",
    "3.2 Binarised Repository  \n",
    "3.3 Hog Repository  \n",
    "3.4 ROS Repository \n",
    "3.5 Class Decomposition  \n",
    " \n",
    "  \n",
    "Each Experiment will be implemented with a stratified fivefold cross validation and compared on their accuracy. With the results discussed in Section 4.1. The original repository will provide detailed steps for which each following repository will follow. Initially Support Vector Machine and Random Forest will be applied to the dataset before a cross validation function measures the accuracy of each classifier.  Then a manual stratified K-fold cross validation split will be applied to the neural network and the convolutional neural network ensuring each model measures mean accuracy. A random seed of 123 is applied to each experiment to ensure reproducibility.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Original Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#set target set to an array\n",
    "target = np.array(target)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(originalrepo, target, stratify=target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. Support Vector Machine(SVM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM is an algorithm that locates a line (or hyperplane) dividing data between different groups. The algorithm collects the input data as input and generates a hyperplane that aims to classify the correct groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# initiatiate the SVC\n",
    "svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "svc_fit = svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "svc_pred = svc_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "svc_ac = cross_val_score(svc_model, originalrepo, target, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests (FR) is a algorithm designed to create a forest from decision trees that individually vote on an instance to create a prediction. The algorithm uses a techniques of splitting a node from trees to determine the best feature from a random subset of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "rf_fit = rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "rf_ac = cross_val_score(rf_model, originalrepo, target, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Neural Network (NN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network below contains three layers: an input layer, a variety of hidden layers, and an output layer. To generate an output layer with the prediction of gender and mask detection. Results are placed in a accuracy per fold folder and a loss per fold folder, to be evaluated in Section 4.1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Keras backend environment for CNN\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to implement NN, the target dataframe to categorical and one hot encodede\n",
    "#convert target dataset to a numpy array for the NN\n",
    "target = np.array(target)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 4\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask\", \"femalenomask\", \"malemask\", \"malenomask\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels = np.zeros((len(target), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1273, 10000) (1273, 4) (1273, 10000) (1273, 4)\n"
     ]
    }
   ],
   "source": [
    "print(originalrepo.shape, ohe_labels.shape, originalrepo.shape, ohe_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 1ms/step - loss: 15.5010 - accuracy: 0.2870\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3807 - accuracy: 0.2695\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3789 - accuracy: 0.2915\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.2688\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3835 - accuracy: 0.2656\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3807 - accuracy: 0.2745\n",
      "Score for fold 1: loss of 1.3807449340820312; accuracy of 27.450981736183167%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 17.3235 - accuracy: 0.2351\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3839 - accuracy: 0.2552\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3816 - accuracy: 0.2597\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3802 - accuracy: 0.2886\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3791 - accuracy: 0.2692\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3810632228851318; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 1ms/step - loss: 8.6577 - accuracy: 0.2469\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3836 - accuracy: 0.2508\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3846 - accuracy: 0.2779\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3862 - accuracy: 0.2467\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.2726\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3811 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.3810920715332031; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 1ms/step - loss: 200.4121 - accuracy: 0.2182\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3817 - accuracy: 0.2892\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3802 - accuracy: 0.2795\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3829 - accuracy: 0.2645\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3855 - accuracy: 0.2708\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3814 - accuracy: 0.2717\n",
      "Score for fold 4: loss of 1.381436824798584; accuracy of 27.165353298187256%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 52.0991 - accuracy: 0.2609\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3846 - accuracy: 0.2787\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3852 - accuracy: 0.2736\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3840 - accuracy: 0.2624\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3817 - accuracy: 0.2699\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3815 - accuracy: 0.2795\n",
      "Score for fold 5: loss of 1.3814737796783447; accuracy of 27.952754497528076%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "fold_no = 1\n",
    "# Define per-fold score containers \n",
    "acc_per_fold_nn = []\n",
    "loss_per_fold_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "data = originalrepo\n",
    "#create train and test set with manual cross validation\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    #Initiating a sequential model\n",
    "    nn_model = Sequential()\n",
    "    #With the flattened original repository as the input layer. \n",
    "    #Each hidden layer uses the input from the previous layer.\n",
    "    #Assigns numerical weights, combines them before introducing the relu activation function. \n",
    "    #As the size of the images were 100 x 100 this has resulted in the 10000 input shape\n",
    "    #The input nodes have two layers of 10 and before reducing to 4 to represent the number of classes. \n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    #The model is then compiled and trained on the training data before applied to the test set.\n",
    "    #Using categorical cross entropy, the Adam optimiser and evaluating its accuracy. \n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Convolutional Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNN) share the basic components of a neural network however contain additional layers to improve accuracy on classifying data. CNN perform best when the image data is normalised and converted to a float32 data type.  The training data will be reshaped into four dimensions before passing through and compiled with the Adam optimiser and the loss and accuracy measured for each CV fold. With the steps annotated throught the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 27s 129ms/step - loss: 1.4901 - accuracy: 0.3131\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 26s 129ms/step - loss: 1.2076 - accuracy: 0.5035\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.9337 - accuracy: 0.6511\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.5709 - accuracy: 0.7723\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.3409 - accuracy: 0.8873\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.2790 - accuracy: 0.5804\n",
      "Score for fold 1: loss of 1.278969645500183; accuracy of 58.03921818733215%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.4945 - accuracy: 0.3376\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 1.0198 - accuracy: 0.5901\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.7368 - accuracy: 0.7241\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.4072 - accuracy: 0.8630\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 0.2515 - accuracy: 0.9183\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 1.4431 - accuracy: 0.5804\n",
      "Score for fold 2: loss of 1.4431427717208862; accuracy of 58.03921818733215%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 1.5227 - accuracy: 0.3376\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 30s 146ms/step - loss: 0.9952 - accuracy: 0.6109\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.6558 - accuracy: 0.7415\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.4123 - accuracy: 0.8429\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 0.2997 - accuracy: 0.8968\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.4639 - accuracy: 0.6235\n",
      "Score for fold 3: loss of 1.4639337062835693; accuracy of 62.352943420410156%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 136ms/step - loss: 1.4843 - accuracy: 0.3614\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.0717 - accuracy: 0.5965\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.7232 - accuracy: 0.7456\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.4413 - accuracy: 0.8385\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 0.2971 - accuracy: 0.8900\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 1.4020 - accuracy: 0.5748\n",
      "Score for fold 4: loss of 1.4019635915756226; accuracy of 57.48031735420227%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 139ms/step - loss: 1.5018 - accuracy: 0.3295\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 1.0528 - accuracy: 0.5919\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 0.7786 - accuracy: 0.7010\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 0.4766 - accuracy: 0.8257\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.2585 - accuracy: 0.9034\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 1.4868 - accuracy: 0.5472\n",
      "Score for fold 5: loss of 1.486788034439087; accuracy of 54.72440719604492%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define per-fold score containers \n",
    "acc_per_fold_cnn = []\n",
    "loss_per_fold_cnn = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "data = originalrepo\n",
    "fold_no = 1\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "\n",
    "    #The CNN will be sequential with two convolutional layers,\n",
    "    #It computes 32 filters over the input with a response map that is 26 x 26 in size.\n",
    "    # The size of the patches is 3 x 3 and the depth of the output feature map is 32.\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    #max pooling of size 2×2 \n",
    "    #xtracts windows from the input much like a convolution and halves the feature map. \n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #dropout of 0.25. \n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    #Before flattening and adding a dense layer with relu activation.  \n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    #A dropout value of 0.5, and seond dense layer with softmax activation function is passed through. \n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Binarised Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(binarisedrepo, target, stratify=target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initiatiate the SVC\n",
    "bin_svc_model = SVC()\n",
    "\n",
    "# Fit theclassifier to the training data\n",
    "bin_svc_fit = bin_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the model with the test data\n",
    "bin_svc_pred = bin_svc_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "bin_svc_ac = cross_val_score(bin_svc_model, binarisedrepo, target, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initiatiate the RandomForestClassifier\n",
    "bin_rf_model = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "bin_rf_fit = bin_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the model with the test data\n",
    "bin_rf_pred = bin_rf_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "bin_rf_ac = cross_val_score(bin_rf_model, binarisedrepo, target, cv=5, scoring = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3.2.3. NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 10.9603 - accuracy: 0.2125\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7602 - accuracy: 0.2678\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3886 - accuracy: 0.2728\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3694 - accuracy: 0.2537\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3582 - accuracy: 0.2761\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4576 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.4576337337493896; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 7.3442 - accuracy: 0.2556\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3646 - accuracy: 0.2823\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3572 - accuracy: 0.3079\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3593 - accuracy: 0.2947\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3627 - accuracy: 0.3006\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4663 - accuracy: 0.2824\n",
      "Score for fold 2: loss of 1.4662619829177856; accuracy of 28.23529541492462%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 17.8980 - accuracy: 0.2412\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.6220 - accuracy: 0.2644\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.6373 - accuracy: 0.2706\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3659 - accuracy: 0.2972\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3872 - accuracy: 0.2890\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3836 - accuracy: 0.2863\n",
      "Score for fold 3: loss of 1.3836184740066528; accuracy of 28.62745225429535%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 35.3573 - accuracy: 0.2589\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.4153 - accuracy: 0.2706\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.4051 - accuracy: 0.2974\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3706 - accuracy: 0.2595\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3550 - accuracy: 0.2855\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.4126 - accuracy: 0.2677\n",
      "Score for fold 4: loss of 1.4126108884811401; accuracy of 26.771652698516846%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 32.8321 - accuracy: 0.2551\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 2.4571 - accuracy: 0.2809\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.6711 - accuracy: 0.2755\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3817 - accuracy: 0.2555\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.3496 - accuracy: 0.2900\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.5025 - accuracy: 0.2598\n",
      "Score for fold 5: loss of 1.5024993419647217; accuracy of 25.984251499176025%\n"
     ]
    }
   ],
   "source": [
    "data = binarisedrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_bin_nn = []\n",
    "loss_per_fold_bin_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create train and test set \n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    #create model architecture\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_bin_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_bin_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 142ms/step - loss: 1.5274 - accuracy: 0.2984\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.0760 - accuracy: 0.5892\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 0.4713 - accuracy: 0.8436\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 30s 148ms/step - loss: 0.1626 - accuracy: 0.9479s - l - ETA: 0s - loss: 0.1622 - accura\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 31s 153ms/step - loss: 0.1153 - accuracy: 0.9510\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.9432 - accuracy: 0.4392\n",
      "Score for fold 1: loss of 1.9431887865066528; accuracy of 43.92156898975372%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 1.4562 - accuracy: 0.2932\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 136ms/step - loss: 1.0024 - accuracy: 0.6046\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 0.3258 - accuracy: 0.8987\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 0.1749 - accuracy: 0.9369\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.0776 - accuracy: 0.9760\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 2.3207 - accuracy: 0.4353\n",
      "Score for fold 2: loss of 2.3207263946533203; accuracy of 43.529412150382996%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 136ms/step - loss: 1.4147 - accuracy: 0.2833\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 1.1154 - accuracy: 0.5514\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.5630 - accuracy: 0.7948\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 137ms/step - loss: 0.1926 - accuracy: 0.9327\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 135ms/step - loss: 0.1196 - accuracy: 0.9612\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.9283 - accuracy: 0.4627\n",
      "Score for fold 3: loss of 1.9283020496368408; accuracy of 46.27451002597809%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 139ms/step - loss: 1.4498 - accuracy: 0.2559\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 31s 150ms/step - loss: 1.1376 - accuracy: 0.5386\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 0.5534 - accuracy: 0.8109\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 0.2271 - accuracy: 0.9336\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.1392 - accuracy: 0.9527\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 2.2581 - accuracy: 0.4094\n",
      "Score for fold 4: loss of 2.2580740451812744; accuracy of 40.94488322734833%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 142ms/step - loss: 1.4679 - accuracy: 0.2672\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.1476 - accuracy: 0.4988\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.6382 - accuracy: 0.7736\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.2238 - accuracy: 0.9370\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 30s 148ms/step - loss: 0.1059 - accuracy: 0.9659\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 2.0152 - accuracy: 0.4685\n",
      "Score for fold 5: loss of 2.0152461528778076; accuracy of 46.85039222240448%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = binarisedrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_bin_cnn = []\n",
    "loss_per_fold_bin_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create train and test set \n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    #create model architecture\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_bin_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_bin_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Hog Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hogrepo, target, stratify=target, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "hog_svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "hog_svc_fit = hog_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "hog_svc_pred = hog_svc_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "hog_svc_ac = cross_val_score(hog_svc_model, hogrepo, target, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "hog_rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "hog_rf_fit = hog_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "hog_rf_pred = hog_rf_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "hog_rf_ac = cross_val_score(hog_rf_model, hogrepo, target, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3. NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3866 - accuracy: 0.2873\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3250 - accuracy: 0.3748\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.2429 - accuracy: 0.4461\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.1295 - accuracy: 0.5550\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.0151 - accuracy: 0.5835\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.4275\n",
      "Score for fold 1: loss of 1.3291131258010864; accuracy of 42.74509847164154%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 1ms/step - loss: 1.3768 - accuracy: 0.2775\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3172 - accuracy: 0.3358\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.2693 - accuracy: 0.3813\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.1782 - accuracy: 0.4191\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.0875 - accuracy: 0.5238\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2957 - accuracy: 0.4196\n",
      "Score for fold 2: loss of 1.2956912517547607; accuracy of 41.960784792900085%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3824 - accuracy: 0.2877\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.2840 - accuracy: 0.3942\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.1804 - accuracy: 0.4676\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.1106 - accuracy: 0.5398\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.0244 - accuracy: 0.5554\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2528 - accuracy: 0.4000\n",
      "Score for fold 3: loss of 1.2528339624404907; accuracy of 40.00000059604645%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3806 - accuracy: 0.2902\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3186 - accuracy: 0.3482\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.2205 - accuracy: 0.4631\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.0939 - accuracy: 0.5637\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.5738\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2944 - accuracy: 0.4213\n",
      "Score for fold 4: loss of 1.294379711151123; accuracy of 42.12598502635956%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.3831 - accuracy: 0.2995\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.3230 - accuracy: 0.3901\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.2313 - accuracy: 0.4550\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.2153 - accuracy: 0.4500\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 1.1355 - accuracy: 0.5321\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.2930 - accuracy: 0.4449\n",
      "Score for fold 5: loss of 1.2929898500442505; accuracy of 44.48818862438202%\n"
     ]
    }
   ],
   "source": [
    "data = hogrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_nn = []\n",
    "loss_per_fold_hog_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create train and test set \n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    #create model architecture\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(1800,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1273, 1800), (1273, 4))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hogrepo.shape, ohe_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 6s 24ms/step - loss: 1.3861 - accuracy: 0.2532\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3821 - accuracy: 0.2802\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3809 - accuracy: 0.2521\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3851 - accuracy: 0.2530\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3796 - accuracy: 0.2797\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3807 - accuracy: 0.2784\n",
      "Score for fold 1: loss of 1.380671739578247; accuracy of 27.843138575553894%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 6s 25ms/step - loss: 1.3865 - accuracy: 0.2376\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 5s 25ms/step - loss: 1.3827 - accuracy: 0.2914\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 5s 24ms/step - loss: 1.3797 - accuracy: 0.2732\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 4s 22ms/step - loss: 1.3864 - accuracy: 0.2432 0s - loss: 1.3867 - accura\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 4s 22ms/step - loss: 1.3798 - accuracy: 0.2744\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3807 - accuracy: 0.2784\n",
      "Score for fold 2: loss of 1.3807339668273926; accuracy of 27.843138575553894%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3873 - accuracy: 0.2272\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 4s 21ms/step - loss: 1.3827 - accuracy: 0.2842\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 4s 22ms/step - loss: 1.3829 - accuracy: 0.2772\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3816 - accuracy: 0.2807\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3838 - accuracy: 0.2791\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3808 - accuracy: 0.2784\n",
      "Score for fold 3: loss of 1.3807625770568848; accuracy of 27.843138575553894%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 6s 22ms/step - loss: 1.3938 - accuracy: 0.2589\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3813 - accuracy: 0.2748\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3800 - accuracy: 0.2796\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3779 - accuracy: 0.2941\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3782 - accuracy: 0.2658\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3811 - accuracy: 0.2795\n",
      "Score for fold 4: loss of 1.381062626838684; accuracy of 27.952754497528076%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3861 - accuracy: 0.2831\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3842 - accuracy: 0.2647\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3813 - accuracy: 0.2919\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 5s 23ms/step - loss: 1.3812 - accuracy: 0.2757\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 5s 22ms/step - loss: 1.3795 - accuracy: 0.2759\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3811 - accuracy: 0.2717\n",
      "Score for fold 5: loss of 1.3810559511184692; accuracy of 27.165353298187256%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = hogrepo\n",
    "fold_no = 1\n",
    "\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_cnn = []\n",
    "loss_per_fold_hog_cnn = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create train and test set \n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels[train_index], ohe_labels[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 10, 180, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 10, 180, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "\n",
    "    #create model architecture\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(10,180,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. ROS Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hogrepo_ros, target_ros, stratify=target_ros, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "hogros_svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "hogros_svc_fit = hogros_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "hogros_svc_pred = hogros_svc_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "hogros_svc_ac = cross_val_score(hogros_svc_model, hogrepo_ros, target_ros, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "hogros_rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit the classifier to the training data\n",
    "hogros_rf_fit = hogros_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "hogros_rf_pred = hogros_rf_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "hogros_rf_ac = cross_val_score(hogros_rf_model, hogrepo_ros, target_ros, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3. NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the ROS repository has augmented the shape of the data compared to the previous repositories resulting in the 1800 shape compared to 10000. \n",
    "#This is reflected in the input shape layer of the NN and CNN model architecture. \n",
    "\n",
    "#convert target dataset to a numpy array for the NN\n",
    "target_ros = np.array(target_ros)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 4\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask\",  \"femalenomask\", \"malemask\", \"malenomask\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels_ros = np.zeros((len(target_ros), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target_ros)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target_ros[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels_ros[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 1.3835 - accuracy: 0.2502\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 1.3211 - accuracy: 0.3874\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 1.2038 - accuracy: 0.4636\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 1.1005 - accuracy: 0.5462\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.9993 - accuracy: 0.5821\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.2507 - accuracy: 0.4507\n",
      "Score for fold 1: loss of 1.2507293224334717; accuracy of 45.07042169570923%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 1s 1ms/step - loss: 1.3699 - accuracy: 0.2925\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.2812 - accuracy: 0.3610\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.1866 - accuracy: 0.4903\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.0807 - accuracy: 0.5582\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.0228 - accuracy: 0.5731\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.2243 - accuracy: 0.4437\n",
      "Score for fold 2: loss of 1.224323034286499; accuracy of 44.36619579792023%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 1.3873 - accuracy: 0.2374\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.3171 - accuracy: 0.4024\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 1.1634 - accuracy: 0.5017\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.0432 - accuracy: 0.5859\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.9412 - accuracy: 0.6328\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1868 - accuracy: 0.5246\n",
      "Score for fold 3: loss of 1.1868133544921875; accuracy of 52.464789152145386%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 1.3938 - accuracy: 0.2399\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.3183 - accuracy: 0.3680\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.1962 - accuracy: 0.4711\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.0794 - accuracy: 0.5551\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5935\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.1420 - accuracy: 0.5070\n",
      "Score for fold 4: loss of 1.1419552564620972; accuracy of 50.70422291755676%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 1s 2ms/step - loss: 1.3845 - accuracy: 0.3034\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.2833 - accuracy: 0.3899\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 1.1497 - accuracy: 0.4699\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 0s 2ms/step - loss: 1.0660 - accuracy: 0.5380\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 0s 1ms/step - loss: 0.9410 - accuracy: 0.6313\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.3287 - accuracy: 0.4261\n",
      "Score for fold 5: loss of 1.3286994695663452; accuracy of 42.60563254356384%\n"
     ]
    }
   ],
   "source": [
    "data = hogrepo_ros\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_ros_nn = []\n",
    "loss_per_fold_hog_ros_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create test and train set\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_ros.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_ros[train_index], ohe_labels_ros[val_index]\n",
    "    #create model architecture\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(1800,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_ros_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_ros_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.4. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3886 - accuracy: 0.2338\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 6s 28ms/step - loss: 1.3868 - accuracy: 0.2352\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3870 - accuracy: 0.2452 0s - loss: 1.3870 - ac\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3869 - accuracy: 0.2182\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 6s 28ms/step - loss: 1.3867 - accuracy: 0.1972\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.3863 - accuracy: 0.2500\n",
      "Score for fold 1: loss of 1.3862979412078857; accuracy of 25.0%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 8s 29ms/step - loss: 1.3877 - accuracy: 0.1838\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 6s 28ms/step - loss: 1.3866 - accuracy: 0.2168 0s - loss: 1.3866 - accuracy: \n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 1.3866 - accuracy: 0.2453 0s - loss: 1.3866 - ac\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 6s 28ms/step - loss: 1.3867 - accuracy: 0.2388\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 6s 28ms/step - loss: 1.3865 - accuracy: 0.2830 0s - loss:\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.3863 - accuracy: 0.2500\n",
      "Score for fold 2: loss of 1.3863017559051514; accuracy of 25.0%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 7s 28ms/step - loss: 1.3870 - accuracy: 0.2456\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3865 - accuracy: 0.2403\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 1.3865 - accuracy: 0.2404\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3867 - accuracy: 0.2596\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 1.3864 - accuracy: 0.2580\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.3863 - accuracy: 0.2500\n",
      "Score for fold 3: loss of 1.3862967491149902; accuracy of 25.0%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3892 - accuracy: 0.2643\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3873 - accuracy: 0.2342\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 1.3872 - accuracy: 0.2268\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3862 - accuracy: 0.2696\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 7s 29ms/step - loss: 1.3862 - accuracy: 0.2682\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 1.3863 - accuracy: 0.2500\n",
      "Score for fold 4: loss of 1.3863096237182617; accuracy of 25.0%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "228/228 [==============================] - 8s 29ms/step - loss: 1.3887 - accuracy: 0.2494\n",
      "Epoch 2/5\n",
      "228/228 [==============================] - ETA: 0s - loss: 1.3865 - accuracy: 0.25 - 7s 30ms/step - loss: 1.3865 - accuracy: 0.2544\n",
      "Epoch 3/5\n",
      "228/228 [==============================] - 7s 32ms/step - loss: 1.3868 - accuracy: 0.2379 0s - loss: 1.3868 - accuracy: 0.23\n",
      "Epoch 4/5\n",
      "228/228 [==============================] - 7s 31ms/step - loss: 1.3864 - accuracy: 0.2694\n",
      "Epoch 5/5\n",
      "228/228 [==============================] - 7s 30ms/step - loss: 1.3872 - accuracy: 0.2260\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.3863 - accuracy: 0.2500\n",
      "Score for fold 5: loss of 1.386306643486023; accuracy of 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = hogrepo_ros\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_hog_ros_cnn = []\n",
    "loss_per_fold_hog_ros_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create test and train set\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_ros.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_ros[train_index], ohe_labels_ros[val_index]\n",
    "    \n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 18, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 18, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    #create model architecture\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 18,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_hog_ros_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_hog_ros_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Class Decomposition Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(originalrepo, target_cd, stratify=target_cd, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.1. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initiatiate the SVC\n",
    "cd_svc_model = SVC()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "cd_svc_fit = cd_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "cd_svc_pred = cd_svc_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "cd_svc_ac = cross_val_score(cd_svc_model, originalrepo, target_cd, cv=5, scoring = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initiatiate the RandomForestClassifier\n",
    "cd_rf_model = RandomForestClassifier()\n",
    "\n",
    "# fit theclassifier to the training data\n",
    "cd_rf_fit = cd_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# predict the model with the test data\n",
    "cd_rf_pred = cd_rf_model.predict(X_test)\n",
    "\n",
    "#evaluate model\n",
    "cd_rf_ac = cross_val_score(cd_rf_model, originalrepo, target_cd, cv=5, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.3. NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The NN and CNN of the class decomposition model will have extra classifiers. \n",
    "#This results in the target dataframe to be one hot encoded to ensure it reflects the six classifiers within. \n",
    "\n",
    "#convert target dataset to a numpy array for the NN\n",
    "target_cd = np.array(target_cd)\n",
    "\n",
    "# The number of image categories\n",
    "n_categories = 6\n",
    "\n",
    "# The unique values of categories in the data\n",
    "categories = np.array([\"femalemask_c0\", \"femalemask_c1\", \"femalenomask_c0\", \"malemask_c0\", \"malemask_c1\", \"malenomask_c0\"])\n",
    "\n",
    "# Initialize ohe_labels as all zeros\n",
    "ohe_labels_cd = np.zeros((len(target_cd), n_categories))\n",
    "\n",
    "# Loop over the labels\n",
    "for ii in range(len(target_cd)):\n",
    "    # Find the location of this label in the categories variable\n",
    "    jj = np.where(categories== target_cd[ii])\n",
    "    # Set the corresponding zero to one\n",
    "    ohe_labels_cd[ii, jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 3ms/step - loss: 20.1653 - accuracy: 0.2049\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7407 - accuracy: 0.1731\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7251 - accuracy: 0.2053\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7083 - accuracy: 0.2298\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7032 - accuracy: 0.2418\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7046 - accuracy: 0.2235\n",
      "Score for fold 1: loss of 1.7046458721160889; accuracy of 22.35294133424759%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 27.0000 - accuracy: 0.2166\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.7582 - accuracy: 0.2094\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.7395 - accuracy: 0.2448\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7198 - accuracy: 0.2413\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7188 - accuracy: 0.2320\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.7140 - accuracy: 0.2235\n",
      "Score for fold 2: loss of 1.7140083312988281; accuracy of 22.35294133424759%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 18.5703 - accuracy: 0.1904\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7534 - accuracy: 0.2331\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7290 - accuracy: 0.2459\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7095 - accuracy: 0.2248\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7112 - accuracy: 0.2226 ETA: 0s - loss: 1.7243 - \n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.7049 - accuracy: 0.2235\n",
      "Score for fold 3: loss of 1.7049304246902466; accuracy of 22.35294133424759%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 12.8096 - accuracy: 0.2029\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 1.7497 - accuracy: 0.2260\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7101 - accuracy: 0.2120\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7190 - accuracy: 0.2100\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.6976 - accuracy: 0.2377\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.7044 - accuracy: 0.2244\n",
      "Score for fold 4: loss of 1.7043981552124023; accuracy of 22.440944612026215%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 1s 2ms/step - loss: 23.6246 - accuracy: 0.2225\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7400 - accuracy: 0.2388\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7127 - accuracy: 0.2119\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7088 - accuracy: 0.2221\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 0s 2ms/step - loss: 1.7018 - accuracy: 0.2245\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1.6941 - accuracy: 0.2244\n",
      "Score for fold 5: loss of 1.694091796875; accuracy of 22.440944612026215%\n"
     ]
    }
   ],
   "source": [
    "#Changes are also found within NN and CNN architecture in the final layer of each model before compilation.  \n",
    "data = originalrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold_cd_nn = []\n",
    "loss_per_fold_cd_nn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create test and train set\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_cd.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_cd[train_index], ohe_labels_cd[val_index]\n",
    "    #create model architecture\n",
    "    nn_model = Sequential()\n",
    "    nn_model.add(Dense(10, input_shape=(10000,), activation='relu'))\n",
    "    nn_model.add(Dense(10, activation='relu'))\n",
    "    nn_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = nn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = nn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {nn_model.metrics_names[0]} of {scores[0]}; {nn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_cd_nn.append(scores[1] * 100)\n",
    "    loss_per_fold_cd_nn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.4. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 0\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 143ms/step - loss: 2.0541 - accuracy: 0.2636\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 30s 145ms/step - loss: 1.5203 - accuracy: 0.3914\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 30s 147ms/step - loss: 1.2276 - accuracy: 0.5444\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 0.8749 - accuracy: 0.6914\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.5335 - accuracy: 0.8230\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 1.8697 - accuracy: 0.5176\n",
      "Score for fold 1: loss of 1.8696988821029663; accuracy of 51.76470875740051%\n",
      "Training for fold 1\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.8403 - accuracy: 0.2532\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 1.4302 - accuracy: 0.4407\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 143ms/step - loss: 1.0995 - accuracy: 0.6050\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 29s 142ms/step - loss: 0.8954 - accuracy: 0.6801\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 141ms/step - loss: 0.5760 - accuracy: 0.8188\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 1.3440 - accuracy: 0.4980\n",
      "Score for fold 2: loss of 1.343989372253418; accuracy of 49.803921580314636%\n",
      "Training for fold 2\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 1.8287 - accuracy: 0.2605\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 144ms/step - loss: 1.3581 - accuracy: 0.4729\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 138ms/step - loss: 1.0122 - accuracy: 0.6229\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 0.6567 - accuracy: 0.7865\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 0.4412 - accuracy: 0.8595\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 1.4316 - accuracy: 0.4706\n",
      "Score for fold 3: loss of 1.4316178560256958; accuracy of 47.05882370471954%\n",
      "Training for fold 3\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 29s 138ms/step - loss: 1.8365 - accuracy: 0.2583\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 1.3511 - accuracy: 0.4723\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 28s 140ms/step - loss: 1.0586 - accuracy: 0.6425\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 0.6254 - accuracy: 0.7532\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 28s 139ms/step - loss: 0.4527 - accuracy: 0.8445\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 1.3293 - accuracy: 0.5276\n",
      "Score for fold 4: loss of 1.3293240070343018; accuracy of 52.75590419769287%\n",
      "Training for fold 4\n",
      "Epoch 1/5\n",
      "204/204 [==============================] - 30s 142ms/step - loss: 1.8806 - accuracy: 0.2634\n",
      "Epoch 2/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 1.3776 - accuracy: 0.4539\n",
      "Epoch 3/5\n",
      "204/204 [==============================] - 29s 145ms/step - loss: 1.0339 - accuracy: 0.6114\n",
      "Epoch 4/5\n",
      "204/204 [==============================] - 28s 140ms/step - loss: 0.8135 - accuracy: 0.6923\n",
      "Epoch 5/5\n",
      "204/204 [==============================] - 29s 140ms/step - loss: 0.4674 - accuracy: 0.8383\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.5054 - accuracy: 0.5118\n",
      "Score for fold 5: loss of 1.5054469108581543; accuracy of 51.18110179901123%\n"
     ]
    }
   ],
   "source": [
    "# Import relevant packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data = originalrepo\n",
    "fold_no = 1\n",
    "# Define per-fold score containers \n",
    "acc_per_fold_cd_cnn = []\n",
    "loss_per_fold_cd_cnn = []\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#create test and train set\n",
    "for i, (train_index, val_index) in enumerate(kfold.split(data, ohe_labels_cd.argmax(1))):\n",
    "    x_train_kf, x_val_kf = data[train_index], data[val_index]\n",
    "    y_train_kf, y_val_kf = ohe_labels_cd[train_index], ohe_labels_cd[val_index]\n",
    "\n",
    "    \n",
    "    # Reshape the dataset into 4D array\n",
    "    x_train_kf = x_train_kf.reshape(x_train_kf.shape[0], 100, 100, 1)\n",
    "    x_val_kf = x_val_kf.reshape(x_val_kf.shape[0], 100, 100, 1)\n",
    "\n",
    "    # Convert dataset into a float32\n",
    "    x_train_kf = x_train_kf.astype('float32')\n",
    "    x_val_kf = x_val_kf.astype('float32')\n",
    "\n",
    "    # Normalise the dataset\n",
    "    x_train_kf /= 255\n",
    "    x_val_kf /= 255\n",
    "    \n",
    "    #create model architecture\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100,100,1)))\n",
    "    cnn_model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(128, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    cnn_model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {i}')\n",
    "\n",
    "    # Fit data to model\n",
    "    history = cnn_model.fit(x_train_kf, y_train_kf,\n",
    "    batch_size=5,\n",
    "    epochs=5)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = cnn_model.evaluate(x_val_kf, y_val_kf)\n",
    "    print(f'Score for fold {fold_no}: {cnn_model.metrics_names[0]} of {scores[0]}; {cnn_model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_cd_cnn.append(scores[1] * 100)\n",
    "    loss_per_fold_cd_cnn.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy results from each dataset and classifier are collected below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Repository\n",
      "Mean Accuracy for SVM:  55.924656476763936\n",
      "Mean Accuracy for RF:  52.23282383819669\n",
      "Mean Accuracy for NN:  27.651073336601257\n",
      "Mean Accuracy for CNN:  58.12722086906433\n",
      "\n",
      "Binarised Repository\n",
      "Mean Accuracy for SVM:  45.320673151150224\n",
      "Mean Accuracy for RF:  43.98733981781689\n",
      "Mean Accuracy for NN:  27.492358088493347\n",
      "Mean Accuracy for CNN:  44.30415332317352\n",
      "\n",
      "Hog Repository\n",
      "Mean Accuracy for SVM:  46.34058977921878\n",
      "Mean Accuracy for RF:  42.651536205033196\n",
      "Mean Accuracy for NN:  42.26401150226593\n",
      "Mean Accuracy for CNN:  27.729504704475403\n",
      "\n",
      "Hog Ros Repository\n",
      "Mean Accuracy for SVM:  54.64788732394366\n",
      "Mean Accuracy for RF:  55.42253521126761\n",
      "Mean Accuracy for NN:  47.04225242137909\n",
      "Mean Accuracy for CNN:  25.0\n",
      "\n",
      "Class Decomposition\n",
      "Mean Accuracy for SVM:  51.76192681797128\n",
      "Mean Accuracy for RF:  48.462868612011725\n",
      "Mean Accuracy for NN:  22.38814264535904\n",
      "Mean Accuracy for CNN:  50.51289200782776\n"
     ]
    }
   ],
   "source": [
    "#calculate mean accuracy per classifier for Original Repository\n",
    "print('\\nOriginal Repository')\n",
    "print('Mean Accuracy for SVM: ',np.mean(svc_ac)*100)\n",
    "print('Mean Accuracy for RF: ',np.mean(rf_ac)*100)\n",
    "print('Mean Accuracy for NN: ',np.mean(acc_per_fold_nn))\n",
    "print('Mean Accuracy for CNN: ',np.mean(acc_per_fold_cnn))\n",
    "\n",
    "#calculate mean accuracy per classifier for Binarised Repository\n",
    "print('\\nBinarised Repository')\n",
    "print('Mean Accuracy for SVM: ',np.mean(bin_svc_ac)*100)\n",
    "print('Mean Accuracy for RF: ',np.mean(bin_rf_ac)*100)\n",
    "print('Mean Accuracy for NN: ',np.mean(acc_per_fold_bin_nn))\n",
    "print('Mean Accuracy for CNN: ',np.mean(acc_per_fold_bin_cnn))\n",
    "\n",
    "#calculate mean accuracy per classifier for Hog Repository\n",
    "print('\\nHog Repository')\n",
    "print('Mean Accuracy for SVM: ',np.mean(hog_svc_ac)*100)\n",
    "print('Mean Accuracy for RF: ',np.mean(hog_rf_ac)*100)\n",
    "print('Mean Accuracy for NN: ',np.mean(acc_per_fold_hog_nn))\n",
    "print('Mean Accuracy for CNN: ',np.mean(acc_per_fold_hog_cnn))\n",
    "\n",
    "#calculate mean accuracy per classifier for Hog Ros Repository\n",
    "print('\\nHog Ros Repository')\n",
    "print('Mean Accuracy for SVM: ',np.mean(hogros_svc_ac)*100)\n",
    "print('Mean Accuracy for RF: ',np.mean(hogros_rf_ac)*100)\n",
    "print('Mean Accuracy for NN: ',np.mean(acc_per_fold_hog_ros_nn))\n",
    "print('Mean Accuracy for CNN: ',np.mean(acc_per_fold_hog_ros_cnn))\n",
    "\n",
    "#calculate mean accuracy per classifier for Class Decomposition\n",
    "print('\\nClass Decomposition')\n",
    "print('Mean Accuracy for SVM: ',np.mean(cd_svc_ac)*100)\n",
    "print('Mean Accuracy for RF: ',np.mean(cd_rf_ac)*100)\n",
    "print('Mean Accuracy for NN: ',np.mean(acc_per_fold_cd_nn))\n",
    "print('Mean Accuracy for CNN: ',np.mean(acc_per_fold_cd_cnn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the collected mean accuracies, it is clear that the classifier with the highest accuracy for mask detection and the gender assignment is the original repository with a CNN at 58% average accuracy with fivefold cross validation. This makes sense due to the design of CNN is aimed for image data \n",
    "\n",
    "All datasets with four classes should have a 25% accuracy considering mathematically the chance of correctly classifying is one in four. This would be 20% accuracy for class decomposition model as it is between one in six classes. This highlights when a model particularly does poorly, such as the CNN for the HOG repository and the HOG ROS repository with the average accuracy of 28% and 25% respectively. Showing a slight improvement than chance and suggesting problems with the model. This seems clear when evaluating the loss function in the CNN in Section 3.3.4 and NN in Section 3.4.3. As the value decreases the model is learning however in these two specific cases this very minimal with their classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Accuracy per Repository\n",
      "Total Mean Accuracy for OR 48.48394363015656\n",
      "Total Mean Accuracy for BR 40.2761310951585\n",
      "Total Mean Accuracy for HOG 39.746410547748326\n",
      "Total Mean Accuracy for HOG ROS 45.52816873914759\n",
      "Total Mean Accuracy for CD 43.28145752079246\n",
      "\n",
      "Mean Accuracy per Classifier\n",
      "Total Mean Accuracy for SVM 50.799146709809584\n",
      "Total Mean Accuracy for RF 48.55142073686523\n",
      "Total Mean Accuracy for NN 33.36756759881973\n",
      "Total Mean Accuracy for CNN 41.1347541809082\n",
      "\n",
      "From the results, it states that the original repository has the greatest accuracy of 49%, compared to the NN, the lowest accuracy, with only 34%. The highest is SVM with 51% average accuracy in correctly classifying the images for gender and mask detection.\n"
     ]
    }
   ],
   "source": [
    "print('\\nMean Accuracy per Repository')\n",
    "print('Total Mean Accuracy for OR', np.mean([(svc_ac)*100, (rf_ac)*100, acc_per_fold_nn, acc_per_fold_cnn]))\n",
    "print('Total Mean Accuracy for BR', np.mean([(bin_svc_ac)*100, (bin_rf_ac)*100, acc_per_fold_bin_nn, acc_per_fold_bin_cnn]))\n",
    "print('Total Mean Accuracy for HOG', np.mean([(hog_svc_ac)*100, (hog_rf_ac)*100, acc_per_fold_hog_nn, acc_per_fold_hog_cnn]))\n",
    "print('Total Mean Accuracy for HOG ROS', np.mean([(hogros_svc_ac)*100, (hogros_rf_ac)*100, acc_per_fold_hog_ros_nn, acc_per_fold_hog_ros_cnn]))\n",
    "print('Total Mean Accuracy for CD', np.mean([(cd_svc_ac)*100, (cd_rf_ac)*100, acc_per_fold_cd_nn, acc_per_fold_cd_cnn]))\n",
    "\n",
    "print('\\nMean Accuracy per Classifier')\n",
    "print('Total Mean Accuracy for SVM', np.mean([(svc_ac)*100, (bin_svc_ac)*100, (hog_svc_ac)*100, (hogros_svc_ac)*100, (cd_svc_ac)*100]))                                             \n",
    "print('Total Mean Accuracy for RF', np.mean([(rf_ac)*100, (bin_rf_ac)*100, (hog_rf_ac)*100, (hogros_rf_ac)*100, (cd_rf_ac)*100]))\n",
    "print('Total Mean Accuracy for NN', np.mean([acc_per_fold_nn, acc_per_fold_bin_nn, acc_per_fold_hog_nn, acc_per_fold_hog_ros_nn, acc_per_fold_cd_nn]))                                           \n",
    "print('Total Mean Accuracy for CNN', np.mean([acc_per_fold_cnn, acc_per_fold_bin_cnn, acc_per_fold_hog_cnn, acc_per_fold_hog_ros_cnn, acc_per_fold_cd_cnn]))\n",
    "\n",
    "print('\\nFrom the repository results, it states that the original repository has the greatest mean accuracy of 48%, compared to the HOG repository, the lowest , with only 39% mean accuracy.\n",
    "print('\\nFrom the classifier results, the highest is SVM with 51% mean accuracy in correctly classifying the images for gender and mask detection. With NN at the lowest with 33% mean accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the best model to classify gender with mask detection is the Random Forest model using CNN from these experiments. However, individually the SVM would be a better classifier choice on average with accuracy and the original repository has highest mean accuracy out of the repositories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.2 Improvements to the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the amount of data, by 1000 images for example, can advance the training of each classifier and enhance its predictions. The better quality the images, the more features to extract to distinguish who has a mask on or what gender. Therefore, accuracy could be improved by increasing the quantity and quality of images.\n",
    "\n",
    "Each classifier can apply additional parameters to improve. Both SVM and RF have tuning capabilities, with SVM offering a variety of kernels and RF providing settings for the number of trees to use. NN and CNN could add additional layers or increase the input nodes for deeper training. By increasing the epochs to around 100 instead of 5 to elevate accuracy. CNN can also include a padding feature which would allow selecting the features in the model to correct predictions.\n",
    "\n",
    "Overall, further experimentation with different data and parameters into each specific classifier could result in a vast improvement. Using additional metrics such as precision, recall and f1 score would also provide a deeper evaluation of the performance of the models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GUPTA, A., 2020. Human Faces, A web scraped dataset of human faces suggested for image processing models. [online]. US: Kaggle. Available from: https://www.kaggle.com/ashwingupta3012/human-faces URL [16th April 2021].\n",
    "\n",
    "LARXEL., 2020. Face Mask Detection. [online]. US: Kaggle. Available from: :https://www.kaggle.com/andrewmvd/face-mask-detection URL [16th April 2021]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
